{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "book: **Data Mining the textbook** (ch. 18.5)  \n",
    "book: **[Mining of Massive Datasets](https://www.cambridge.org/core/books/mining-of-massive-datasets/C1B37BA2CBB8361B94FDD1C6F4E47922)** (ch. 9)  \n",
    "http://infolab.stanford.edu/~ullman/mmds/ch9.pdf  \n",
    "https://towardsdatascience.com/how-to-build-from-scratch-a-content-based-movie-recommender-with-natural-language-processing-25ad400eb243  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Recommender Systems\n",
    "## Utility matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" style=\"padding-left:10px;\" src=\"figures/big-utility-matrix.png\" width=\"40%\"> In a recommendation-system application there are two classes of **entities**\n",
    "  * `users` and `items`\n",
    "  \n",
    "For $n$ **users** and $d$ **items**,  \n",
    "this results in an $n \\times d$ `utility-matrix` $D$  \n",
    "of `utility values`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Different utility matrices\n",
    "The nature of the **utility matrix** has a significant influence on the choice of **recommendation algorithm**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/utility-matrix-example.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Utility matrices with Positive preferences only\n",
    "\n",
    "For example, \n",
    "* a specification of a \"**like**\" option on a social networking site, \n",
    "* the **browsing of an item** at an online site, \n",
    "* the **buying** of a specified **quantity** of an item. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Utility matrices with Positive and Negative preferences (ratings)\n",
    "\n",
    "* The **user** specifies the **ratings** that represent their **like** or **dislike** for the **item**. \n",
    "* The incorporation of user dislike in the analysis is significant because it makes the **problem more complex** and often requires some changes to the underlying algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Loading  [MovieLens 100K](https://grouplens.org/datasets/movielens/) Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading ratings file:\n",
    "ratings = pd.read_csv('data/ml-100k/u.data', sep='\\t', names=['user_id', 'movie_id', 'rating', 'unix_timestamp'],  encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ratings.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Create the utility matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "max_user  = int(ratings[\"user_id\"].max() + 1)\n",
    "max_movie = int(ratings[\"movie_id\"].max() + 1)\n",
    "\n",
    "m = np.zeros((max_user, max_movie))\n",
    "m[ratings[\"user_id\"], ratings[\"movie_id\"]] = ratings[\"rating\"]\n",
    "plt.imshow(m, interpolation='nearest');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Long Tail\n",
    "\n",
    "**Physical delivery systems** are characterized by a scarcity of resources. <img align=\"right\" style=\"padding-left:10px;\" src=\"figures/long_tail_final.png\" width=\"50%\">  \n",
    "**On-line stores** can make anything that exists available to the customer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Applications of Recommendation Systems\n",
    "1. **Product Recommendations**: Amazon or similar on-line vendors  \n",
    "   Example of similarity: *purchasing decisions made by similar customers*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "2. **Movie Recommendations**: the Netflix example...  \n",
    "   Example of similarity: ratings provided by similar users \n",
    "   *Netflix offered a prize of one million dollars for the first algorithm that could beat its own recommendation system by 10%.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "3. **News Articles**: identify articles of interest to readers.  \n",
    "   Example of similarity: important words in the documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "4. The **Runner-Recommender** of workout and nutrition for runners  \n",
    "   based  on  runner  profile,  preferences... \n",
    "5. The **Student-Recommender** of courses  \n",
    "   based  on  student  profile,  preferences... \n",
    "6. **etc**..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How to enhance Recommendations?\n",
    "\n",
    "Recommendations can also be enhanced with the use of **content** in the **user and item representations**.\n",
    "1. **Content-based filtering**: users and items are both associated with feature-based descriptions. \n",
    "   * For example, item profiles can be determined by using the **text of the item description**.\n",
    "2. **Collaborative filtering**: is the leveraging of the user preferences in the form of ratings or buying behavior in a “collaborative” way, for the benefit of all users. \n",
    "\n",
    "The two models are not exclusive.  \n",
    "It is often possible to combine content-based methods with collaborative filtering methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "|content-based-filters | collaborative-based-filters|\n",
    "| :-:| :-:|\n",
    "|<img src=\"figures/content-based-filters.png\" width=\"40%\"> | <img src=\"figures/collaborative-based-filters.png\" width=\"55%\">|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Content-Based Recommendations\n",
    "\n",
    "**Content based filtering** uses `characteristics` or `properties` of an **item** to serve recommendations. \n",
    "* Characteristic information includes:\n",
    "  * Characteristics of **Items** \n",
    "    * Keywords\n",
    "    * Attributes\n",
    "  * Characteristics of **Users** \n",
    "    * specified demographic profile, \n",
    "    * specified interests at registration time, \n",
    "    * the product description of the items bought, \n",
    "    * and so on. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Movie recommendation system based on item content\n",
    "\n",
    "Characteristics for the **item** `Harry Potter and the Sorcerer’s Stone` might include:\n",
    "* **Director Name** – Chris Columbus\n",
    "* **Genres** – Adventure, Fantasy, Family (IMDB)\n",
    "* **Stars** – Daniel Radcliffe, Rupert Grint, Emma Watson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"figures/content-based-filtering-harry-potter.webp\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A **content based recommender system** can now **serve the user**:\n",
    "\n",
    "* **More** Harry Potter Movies\n",
    "* **More** Adventure, Family, or Fantasy Movies\n",
    "* **More** Chris Columbus Movies\n",
    "* **More** Daniel Radcliffe Movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Once the **user makes choices**, the recommender system can serve **more targeted results**.\n",
    "\n",
    "* User chooses `Swiss Army Man` next. <br>\n",
    "  It’s safe to assume the <font style=\"color:blue\">user likes movies starring Daniel Radcliffe</font>. \n",
    "* The system tracks these choices and **begins to recommend Daniel Radcliffe films**.\n",
    "* The system may also show the user more Harry Potter movies. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Movie recommendation system based on user content\n",
    "\n",
    "Content based filtering systems can also serve users items **based on users’ profiles**. \n",
    "* You can create **user profiles** based on **historical actions**. \n",
    "* You can also ask in advance about their **interests** and **preferences**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"figures/user-profile-based-recommender.png\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Item Profiles\n",
    "\n",
    "* In a content-based system, we must construct **for each item a profile**, \n",
    "  * a collection of `important characteristics` of that item.\n",
    "* In the **movie example**\n",
    "  * The set of actors of the movie\n",
    "  * The director\n",
    "  * The year in which the movie was made\n",
    "  * The *genre* of movie (comedies, dramas, romances, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Discovering Features of Documents\n",
    "\n",
    "For items like **document collections** and **images** where it is **not** immediately apparent what the **values of features** should be.\n",
    "* extracting **features from documents**  (news articles, web pages, etc..)\n",
    "* user-supplied or authomatic **features from images** (<font style=\"color:blue\">Fashion E-commerce, artistic paintings, furnitures</font>,...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Obtaining Item Features From Tags\n",
    "\n",
    "We can calculate simple properties of pixels, such as the **average amount of red** in the picture,  \n",
    "but `few users are looking for red pictures` or especially like red pictures.\n",
    "* We can invite users to **tag** the items/images by entering **words or phrases** that describe the item.\n",
    "  * a picture with a lot of red might be tagged “`Tiananmen Square`” \n",
    "  * another is tagged “`sunset at Malibu`”\n",
    "* We can use the **tags** as a **recommendation system**. \n",
    "  * We can recommend other documents with the same tags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Representing Item Profiles\n",
    "Goal for content-based recommendation is to create \n",
    "* an **item profile** consisting of <font style=\"color:blue\">feature-value pairs</font>  \n",
    "  * **boolean**: a vector of 0’s and 1’s, where a 1 represented the occurrence of a word in the document\n",
    "  * **numerical**: for example **screen size** or **disk capacity** for PC’s, should be considered similar if their values do not differ greatly\n",
    "* a **user profile** summarizing the preferences of the user, based of their row of the utility matrix. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Item profile example**\n",
    "\n",
    "* **Features of movies** are the set of **actors** and the **average rating**. \n",
    "  * **movie 1**: $0$ $1$ $1$ $0$ $1$ $1$ $0$ $1$ $3\\alpha$\n",
    "  * **movie 2**: $1$ $1$ $0$ $1$ $0$ $1$ $1$ $0$ $4\\alpha$\n",
    "  \n",
    "$${\\text{similarity}}=\\cos(\\theta )={movie_1\\cdot movie_2 \\over \\|movie_1\\|\\|movie_2\\|}=\\frac{2+12\\alpha^2}{\\sqrt{25+125\\alpha^2+144\\alpha^4}}$$\n",
    "\n",
    "* If we choose $α = 1$, then the cosine is 0.940 $\\rightarrow$ the vectors appear much closer in direction.  \n",
    "* If we use $α = 1/2$, then the cosine is 0.619 $\\rightarrow$ the vectors look quite different. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### User Profiles\n",
    "* We have the **utility matrix** representing the connection between **users** and **items**.\n",
    "* we need to **create vectors** describing the **user’s preferences**.\n",
    "  * using some **aggregation** of the **items profile**\n",
    "  * e.g. the **average** of the components of the vectors representing the item profiles for the items in which the utility matrix has 1 for that user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**User profile example 1**\n",
    "\n",
    "* **Features of movies** are the set of **actors** \n",
    "* **utility matrix** has a 1 if the user has seen the movie and is blank otherwise\n",
    "* If $20\\%$ of the movies that user U likes have `Julia Roberts` as one of the actors, then the user profile for U will have $0.2$ in the component for Julia Roberts.\n",
    "* If the **utility matrix** is **not boolean**, e.g., ratings 1–5, then we can weight the vectors representing the profiles of items by the utility value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**User profile example 2**\n",
    "Same movie information of previous example.\n",
    "* **utility matrix** has nonblank entries that are **ratings** in the 1–5 range\n",
    "* User $U$ gives an **average rating** of 3.\n",
    "  * three movies with `Julia Roberts`, with **ratings** of 3, 4, and 5.\n",
    "  * **subtracting the average**: the average of 3 − 3, 4 − 3, and 5 − 3, that is, a value of 3/3=1.\n",
    "* User $V$ gives an **average rating** of 4.\n",
    "  * three movies with `Julia Roberts`, with **ratings** of 2, 3, and 5.\n",
    "  * **subtracting the average**: the average of 2 − 4, 3 − 4, and 5 − 4, that is, a value of -2/3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recommending Items to Users Based on Content\n",
    "\n",
    "With **profile vectors** for both **users** and **items**, we can \n",
    "* estimate the degree to which a user would prefer an item \n",
    "* by computing the **cosine distance** between the **user’s and item’s vectors**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Classification Algorithms\n",
    "\n",
    "**For each user**, build a <font style=\"color:red\">classifier</font> that **predicts the rating of all items**.\n",
    "* We can use a great number of different classifiers but now we will use a **decision tree**\n",
    "  * the decision would be “`likes`” or “`doesn’t like`”.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Example: news articles**\n",
    "\n",
    "* **Items** are news articles, and **features** are the high-TF.IDF words (keywords) in those documents. \n",
    "* **user** U likes articles about baseball, except articles about the New York Yankees.\n",
    "* The **row** of the **utility matrix** for U has \n",
    "  * 1 if U has **read the article** \n",
    "  * is **blank** if not. \n",
    "* We shall take the 1’s as “`like`” and the blanks as “`doesn’t like`”. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Since U generally **likes baseball**, we might find that the **best keyword** for the root is “`homerun`” OR (“`batter`” AND “`pitcher`”). <img align=\"right\" style=\"padding-left:10px;\" src=\"figures/decision-tree4recommendation-sys.png\" width=\"50%\"> \n",
    "* Items that satisfy the predicate will tend to be positive examples (articles with 1 in the row for U in the utility matrix), and items that fail to satisfy the predicate will tend to be negative examples (blanks in the utility-matrix row for U ). \n",
    "* We can use **one decision tree per user**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Python example: build a simple content-based movie recommender \n",
    "**using Natural Language Processing (NLP)** to <font style=\"color:red\">detect similarities between movies</font> \n",
    "* **Dataset**: top `250 top rated movies` from IMDB.\n",
    "* 250 observations (the movies) and 38 columns. \n",
    "* We are interested only on \n",
    "  * the movie director, \n",
    "  * main actors, \n",
    "  * genre, \n",
    "  * plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Load data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rake_nltk import Rake\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "df = pd.read_csv('https://query.data.world/s/uikepcpffyo2nhig52xxeevdialfl7')\n",
    "\n",
    "df = df[['Title','Genre','Director','Actors','Plot']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Data cleaning**\n",
    "* We are using a `Rake` function to **extract keywords** from the Plot column\n",
    "  * RAKE: `Rapid Automatic Keyword Extraction` algorithm using NLTK\n",
    "* So, instead of using the entire **sentences describing the plot**, we only considered the most relevant words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# initializing the new column\n",
    "df['Key_words'] = \"\"\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    plot = row['Plot']\n",
    "    \n",
    "    # instantiating Rake, by default it uses english stopwords from NLTK\n",
    "    # and discards all puntuation characters as well\n",
    "    r = Rake()\n",
    "\n",
    "    # extracting the words by passing the text\n",
    "    r.extract_keywords_from_text(plot)\n",
    "\n",
    "    # getting the dictionary whith key words as keys and their scores as values\n",
    "    key_words_dict_scores = r.get_word_degrees()\n",
    "    \n",
    "    # assigning the key words to the new column for the corresponding movie\n",
    "    row['Key_words'] = list(key_words_dict_scores.keys())\n",
    "\n",
    "# dropping the Plot column\n",
    "df.drop(columns = ['Plot'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Transforming the **full names of actors and directors in single words** so they are considered as unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discarding the commas between the actors' full names and getting only the first three names\n",
    "df['Actors'] = df['Actors'].map(lambda x: x.split(',')[:3])\n",
    "\n",
    "# putting the genres in a list of words\n",
    "df['Genre'] = df['Genre'].map(lambda x: x.lower().split(','))\n",
    "\n",
    "df['Director'] = df['Director'].map(lambda x: x.split(' '))\n",
    "\n",
    "# merging together first and last name for each actor and director, so it's considered as one word \n",
    "# and there is no mix up between people sharing a first name\n",
    "for index, row in df.iterrows():\n",
    "    row['Actors'] = [x.lower().replace(' ','') for x in row['Actors']]\n",
    "    row['Director'] = ''.join(row['Director']).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# reassigne the index to the movie title column\n",
    "df.set_index('Title', inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Merge all the words into a single column `bag_of_words`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bag_of_words'] = ''\n",
    "columns = df.columns\n",
    "for index, row in df.iterrows():\n",
    "    words = ''\n",
    "    for col in columns:\n",
    "        if col != 'Director':\n",
    "            words = words + ' '.join(row[col])+ ' '\n",
    "        else:\n",
    "            words = words + row[col]+ ' '\n",
    "    row['bag_of_words'] = words\n",
    "    \n",
    "df.drop(columns = [col for col in df.columns if col!= 'bag_of_words'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Modeling**\n",
    "* In order to <font style=\"color:red\">detect similarities between movies</font>, we need to vectorize. \n",
    "* We will use `CountVecorizer`\n",
    "* Once we have the **matrix** containing the count for each word, we can apply the `cosine_similarity` function\n",
    "<img src=\"figures/count_vectorizer_movies.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# instantiating and generating the count matrix\n",
    "# CountVectorizer convert a collection of text documents to a matrix of token counts\n",
    "count = CountVectorizer()\n",
    "count_matrix = count.fit_transform(df['bag_of_words'])\n",
    "# print(count.get_feature_names())\n",
    "# from sparse representation to matrix\n",
    "# print(count_matrix.toarray()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# generating the cosine similarity matrix# genera \n",
    "cosine_sim = cosine_similarity(count_matrix, count_matrix)\n",
    "cosine_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The similarity matrix looks like this\n",
    "<img src=\"figures/similarity_matrix.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Function: the top similar movies**  \n",
    "\n",
    "We can write the actual function that takes a **movie title as input**, and returns the **top 10 similar movies**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# creating a Series for the movie titles so they are associated to an ordered numerical\n",
    "# list I will use in the function to match the indexes\n",
    "indices = pd.Series(df.index)\n",
    "\n",
    "# INPUT: movie title \n",
    "# RETURNS: the top 10 recommended movies\n",
    "def recommendations(title, cosine_sim = cosine_sim):\n",
    "    \n",
    "    # initializing the empty list of recommended movies\n",
    "    recommended_movies = []\n",
    "    \n",
    "    # gettin the index of the movie that matches the title\n",
    "    idx = indices[indices == title].index[0]\n",
    "\n",
    "    # creating a Series with the similarity scores in descending order\n",
    "    score_series = pd.Series(cosine_sim[idx]).sort_values(ascending = False)\n",
    "\n",
    "    # getting the indexes of the 10 most similar movies\n",
    "    top_10_indexes = list(score_series.iloc[1:11].index)\n",
    "    \n",
    "    # populating the list with the titles of the best 10 matching movies\n",
    "    for i in top_10_indexes:\n",
    "        recommended_movies.append(list(df.index)[i])\n",
    "        \n",
    "    return recommended_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Testing the recommender**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "recommendations('Fargo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "recommendations('No Country for Old Men')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "## Practice \n",
    "1. Build a new content-based movie recommender, replacing the cosine_similarity with `sklearn.metrics.pairwise.euclidean_distances`\n",
    "2. Compare some test results\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Neighborhood-Based Methods for Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Graph-Based Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Clustering Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Latent Factor Models"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
