{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "book: \"`Information Extraction: Algorithms and Prospects in a Retrieval Context`\"\n",
    "\n",
    "single input example: https://towardsdatascience.com/named-entity-recognition-and-classification-with-scikit-learn-f05372f07ba2\n",
    "\n",
    "context information: https://www.depends-on-the-definition.com/introduction-named-entity-recognition-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Raw Document data may contain `rich linguistic relations between different entities`. \n",
    "\n",
    "* **One approach**: \n",
    "  * remove stop words, \n",
    "  * stem the data, \n",
    "  * use a bag-of-words representation. \n",
    "\n",
    "* **Other methods**:\n",
    "  * `entity extraction` to determine linguistic relationships.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "<img src=\"figures/information-extraction-intro.jpg\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Information Extraction (IE) systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Find\tand\tunderstand**\tlimited\trelevant\tparts\tof\ttexts\t\n",
    "* **Gather\tinformation**\tfrom\tmany\tpieces\tof\ttext\t\n",
    "* Produce\ta\t**structured\trepresentation**\tof\trelevant\tinformation\n",
    "* Goals:\t\n",
    "  1. Organize\tinformation\tso\tthat\tit\tis\t**useful\tto\tpeople**\t\n",
    "  2. Put\tinformation\tin\ta\t**semantically**\tprecise\t**form**\tthat\tallows\tfurther\tinferences\tto\tbe\tmade\tby\tcomputer\talgorithms\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Named-Entity Recognition (NER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/ner-fig.jpg\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "is an important subtask of **information extraction**. \n",
    "\n",
    "This approach **locates and classifies** <font style=\"color:red\">atomic elements</font> in text into predefined expressions of \n",
    "* names of persons, \n",
    "* organizations, \n",
    "* locations, \n",
    "* actions, \n",
    "* numeric quantities, \n",
    "* and so on.\n",
    "\n",
    "**Atomic elements**: used to understand the structure of sentences and complex events. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example\n",
    "consider the following sentence:\n",
    "\n",
    "> Bill Clinton lives in Chappaqua.\n",
    "\n",
    "Here, \n",
    "* “`Bill Clinton`” is the **name** of a person, \n",
    "* “`Chappaqua`” is the **name** of a place. \n",
    "* The word “`lives`” denotes an **action**. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Named Entity Recognition**, also known as **Entity Extraction** classifies named entities that are present in a text into pre-defined categories like \n",
    "* “individuals”, “companies”, “places”, “organization”, “cities”, “dates”, “product terminologies” etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A\tvery\timportant\tsub-task:\t<font style=\"color:red\">**find**</font>\tand\t<font style=\"color:red\">**classify**</font> names\tin text,   \n",
    "for\texample:\t\n",
    "\n",
    "<img src=\"figures/ner-example.png\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "**Named Entity Extraction** forms a core **subtask** to build knowledge \n",
    "* from semi-structured and unstructured text sources. \n",
    "\n",
    "Some of the **first researchers** working to extract information from unstructured texts recognized the importance of “<font style=\"color:red\">units of information</font>” like \n",
    "* **names** (such as person, organization, and location names) \n",
    "* **numeric expressions** (such as time, date, money, and percent expressions). \n",
    "\n",
    "They coined the term “Named Entity” in 1996 to represent these. \n",
    "\n",
    "`Named Enity Recognition is one of the most common NLP problems.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The\tuses\n",
    "* Named\tentities\tcan\tbe\t**indexed**,\tlinked\toff,\tetc.\t\n",
    "* **Sentiment**\tcan\tbe\tattributed\tto\t`companies`\tor\t`products`\t\n",
    "* A\tlot\tof\t**IE\trelations**\tare\tassociations\tbetween\tnamed\t`entities`\t\n",
    "* For\t**question\tanswering**,\tanswers\tare\toffen\tnamed\t`entities`.\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Use Cases 1: Classifying content for news providers\n",
    "\n",
    "* Named Entity Recognition can automatically **scan entire articles** and reveal which are \n",
    "  * the major `people`, `organizations`, and `places` discussed in them. \n",
    "* Knowing the relevant tags for each article **help in automatically categorizing the articles** in defined hierarchies.\n",
    "\n",
    "<img src=\"figures/ner-doc-classification.png\" width=\"70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Use case 2: Customer Support\n",
    "\n",
    "<img src=\"figures/ner-customer-support.png\" width=\"60%\">\n",
    "\n",
    "* Using Named Entity Recognition we know the entities \n",
    "  * Bandra (**location**) and Fitbit (**Product**). \n",
    "* This can be then used to **categorize** the complaint and **assign it to the relevant department** within the organization that should be handling this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Use case 3: Powering Content Recommendations\n",
    "\n",
    "By **extracting entities** from a particular article and \n",
    "\n",
    "<img src=\"figures/ner-recommendations.png\" width=\"60%\">\n",
    "\n",
    "recommending the other articles which have the **most similar entities** mentioned in them. \n",
    "<img src=\"figures/ner-recommendations2.png\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Entity Extraction\n",
    "The three common methods to approach entity extraction (and recognition)\n",
    "\n",
    "* **Entity lists** — Used when the list of entities is known and finite (e.g., a list of professional `tennis players` from 2013–2014).\n",
    "* **Regular expressions** — Use regular expressions when the entity can be defined by a `pattern`. For example, `credit card numbers` are 16 digits beginning with a 4 (Visa), 5 (Mastercard), 6 (Discover), or 15 numbers beginning with a 34 or 37 (American Express). Regular expressions can reliably find these entities.\n",
    "* **Statistical models** — entities that you cannot exhaustively list or which have too much overlap with non-entities, statistical modeling (a.k.a., **machine learning**) is best as it is context sensitive. Traditional ML and more recent approaches like CNN/RNN are used in this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### IOB Inside–Outside–Beginning (tagging)\n",
    "\n",
    "The **IOB** (short for Inside, Outside, Beginning) is a common tagging format for tagging tokens.\n",
    "\n",
    "* **I-** prefix before a tag indicates that the tag is **inside** a chunk.\n",
    "* **B-** prefix before a tag indicates that the tag is the **beginning** of a chunk.\n",
    "* An **O tag** indicates that a token belongs to no chunk (**outside**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"figures/ner-tags.png\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Evaluation of Named Entity Recognition\t\n",
    "\n",
    "The\textension of \n",
    "* Precision $P=TP/(TP+FP)$\n",
    "* Recall $R=TP/(TP+FN)$\n",
    "* F-measure \n",
    "\n",
    "to sequences\t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**The Named Entity Recognition Task**: Predict entities in a text\t\n",
    " \n",
    "  \n",
    " <img src=\"figures/ner-eval-example.png\" width=\"70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* **Recall** and **precision** are straighforward for tasks like **text categorization**, where there is only one grain size (documents)\n",
    "* For IE/NER task evaluation there are <font style=\"color:blue\">boundary errors</font> (which are **common**):\n",
    "\n",
    "    <font style=\"color:green\">&lt;ORG&gt;</font>First <font style=\"color:red\">Bank of Chicago</font><font style=\"color:green\">&lt;/ORG&gt;</font> announced earnings ... \n",
    "  * Predicted: `Bank of Chicago`      **ORG**\n",
    "  * **FN**: `First Bank of Chicago`\n",
    "  * **FP**: `Bank of Chicago`\n",
    "  * **2 errors**: This counts as both a **fp** and a **fn**\n",
    "  * Selecting <font style=\"color:red\">nothing</font> would have been better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The ML sequence model approach to NER\n",
    "\n",
    "Training \n",
    "1. Collect a set of representative **training documents** \n",
    "2. Label each token for its **entity class** or **other** (O) \n",
    "3. Design **feature** extractors appropriate to the text and classes \n",
    "4. **Train** a **sequence classifier** to predict the labels from the data \n",
    "\n",
    "Testing \n",
    "1. Receive a set of **testing documents** \n",
    "2. Run sequence model inference to **label each token** \n",
    "3. Appropriately output the recognized entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### NER pipeline\t\n",
    "\n",
    " <img src=\"figures/ner-pipeline.png\" width=\"70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Encoding classes for sequence labeling\n",
    "\n",
    " <img src=\"figures/ner-encoding-example.png\" width=\"40%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Features for sequence labeling\n",
    "\n",
    "Words \n",
    "* Current **word** (essentially like a learned dictionary) \n",
    "* Previous/next word (**context**) \n",
    "* Word Shapes\n",
    "\n",
    "Other kinds of inferred linguistic classification \n",
    "* **Part‐of‐speech** tags \n",
    "\n",
    "Label context \n",
    "* Previous (and perhaps next) label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Features: Word Shapes\n",
    "\n",
    "Map **words** to **simplified representation** that encodes attributes such as \n",
    "* length, capitalization, numerals, Greek letters, internal punctuation, etc.\n",
    "\n",
    "<img src=\"figures/word-shape-features.png\" width=\"30%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Named Entity Recognition with Scikit-Learn\n",
    "* How to train **machine learning** models for NER using Scikit-Learn’s libraries\n",
    "* The **goal** is to `develop practical and domain-independent techniques` in order to detect named entities with high accuracy automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Data\n",
    "\n",
    "Extracted from GMB(Groningen Meaning Bank) corpus which is tagged, annotated and built specifically to train the classifier to predict **named entities** such as name, location, etc.\n",
    "\n",
    "The data is feature engineered corpus **annotated with** \n",
    "* **IOB** (Inside–Outside–Beginning) tags \n",
    "* **POS** (Part-Of-Speech) tags \n",
    "\n",
    "that can be found at [Kaggle](https://www.kaggle.com/abhinavwalia95/how-to-loading-and-fitting-dataset-to-scikit/data). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>through</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>London</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>protest</td>\n",
       "      <td>VB</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>war</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>in</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Iraq</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>and</td>\n",
       "      <td>CC</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demand</td>\n",
       "      <td>VB</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>withdrawal</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>British</td>\n",
       "      <td>JJ</td>\n",
       "      <td>B-gpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>troops</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>from</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>that</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>country</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Sentence: 2</td>\n",
       "      <td>Families</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>soldiers</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>killed</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>in</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sentence #           Word  POS    Tag\n",
       "0   Sentence: 1      Thousands  NNS      O\n",
       "1           NaN             of   IN      O\n",
       "2           NaN  demonstrators  NNS      O\n",
       "3           NaN           have  VBP      O\n",
       "4           NaN        marched  VBN      O\n",
       "5           NaN        through   IN      O\n",
       "6           NaN         London  NNP  B-geo\n",
       "7           NaN             to   TO      O\n",
       "8           NaN        protest   VB      O\n",
       "9           NaN            the   DT      O\n",
       "10          NaN            war   NN      O\n",
       "11          NaN             in   IN      O\n",
       "12          NaN           Iraq  NNP  B-geo\n",
       "13          NaN            and   CC      O\n",
       "14          NaN         demand   VB      O\n",
       "15          NaN            the   DT      O\n",
       "16          NaN     withdrawal   NN      O\n",
       "17          NaN             of   IN      O\n",
       "18          NaN        British   JJ  B-gpe\n",
       "19          NaN         troops  NNS      O\n",
       "20          NaN           from   IN      O\n",
       "21          NaN           that   DT      O\n",
       "22          NaN        country   NN      O\n",
       "23          NaN              .    .      O\n",
       "24  Sentence: 2       Families  NNS      O\n",
       "25          NaN             of   IN      O\n",
       "26          NaN       soldiers  NNS      O\n",
       "27          NaN         killed  VBN      O\n",
       "28          NaN             in   IN      O\n",
       "29          NaN            the   DT      O"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/ner_dataset.csv', encoding = \"ISO-8859-1\")\n",
    "# The entire data set can not be fit into the memory of a single computer, \n",
    "# so we select the first 100,000 records,\n",
    "df = df[:10000]\n",
    "df.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Entities\n",
    "\n",
    "* geo = Geographical Entity\n",
    "* org = Organization\n",
    "* per = Person\n",
    "* gpe = Geopolitical Entity\n",
    "* tim = Time indicator\n",
    "* art = Artifact\n",
    "* eve = Event\n",
    "* nat = Natural Phenomenon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence #    9543\n",
       "Word             0\n",
       "POS              0\n",
       "Tag              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* there are many **NaN** values in ‘`Sentence #`” column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "We fill NaN by preceding values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS Tag\n",
       "0  Sentence: 1      Thousands  NNS   O\n",
       "1  Sentence: 1             of   IN   O\n",
       "2  Sentence: 1  demonstrators  NNS   O\n",
       "3  Sentence: 1           have  VBP   O\n",
       "4  Sentence: 1        marched  VBN   O"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.fillna(method='ffill')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We have 457 sentences that contain 2746 unique words and tagged by 17 tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(457, 2746, 17)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sentence #'].nunique(), df.Word.nunique(), df.Tag.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The tags are not evenly distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-art</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B-eve</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B-geo</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B-gpe</td>\n",
       "      <td>303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B-nat</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B-org</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B-per</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>B-tim</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I-art</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I-eve</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I-geo</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I-gpe</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>I-nat</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>I-org</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>I-per</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>I-tim</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>O</td>\n",
       "      <td>8483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Tag  counts\n",
       "0   B-art      28\n",
       "1   B-eve      10\n",
       "2   B-geo     244\n",
       "3   B-gpe     303\n",
       "4   B-nat       5\n",
       "5   B-org     176\n",
       "6   B-per     160\n",
       "7   B-tim     149\n",
       "8   I-art      20\n",
       "9   I-eve      10\n",
       "10  I-geo      31\n",
       "11  I-gpe      20\n",
       "12  I-nat       2\n",
       "13  I-org     140\n",
       "14  I-per     206\n",
       "15  I-tim      13\n",
       "16      O    8483"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Tag').size().reset_index(name='counts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Transform text to vector \n",
    "\n",
    "we use DictVectorizer and then split to train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS\n",
       "0  Sentence: 1      Thousands  NNS\n",
       "1  Sentence: 1             of   IN\n",
       "2  Sentence: 1  demonstrators  NNS\n",
       "3  Sentence: 1           have  VBP\n",
       "4  Sentence: 1        marched  VBN"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop('Tag', axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Sentence #', 'Word', 'POS'], dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 3242)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = DictVectorizer(sparse=False)\n",
    "X = v.fit_transform(X.to_dict('records'))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "y = df.Tag.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-art',\n",
       " 'B-eve',\n",
       " 'B-geo',\n",
       " 'B-gpe',\n",
       " 'B-nat',\n",
       " 'B-org',\n",
       " 'B-per',\n",
       " 'B-tim',\n",
       " 'I-art',\n",
       " 'I-eve',\n",
       " 'I-geo',\n",
       " 'I-gpe',\n",
       " 'I-nat',\n",
       " 'I-org',\n",
       " 'I-per',\n",
       " 'I-tim',\n",
       " 'O']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = classes.tolist()\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 3242), (10000,))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6700, 3242), (6700,))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Perceptron\n",
    "\n",
    "* We are using algorithms supporting `partial_fit` because our dataset is really big. \n",
    "* Instead of running into possible memory problems you perform your **fitting in smaller batches**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Because tag “O” (outside) is the **most common tag** and it will make our results look much better than they actual are. \n",
    "* We **remove tag “O”** when we evaluate classification metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-art',\n",
       " 'B-eve',\n",
       " 'B-geo',\n",
       " 'B-gpe',\n",
       " 'B-nat',\n",
       " 'B-org',\n",
       " 'B-per',\n",
       " 'B-tim',\n",
       " 'I-art',\n",
       " 'I-eve',\n",
       " 'I-geo',\n",
       " 'I-gpe',\n",
       " 'I-nat',\n",
       " 'I-org',\n",
       " 'I-per',\n",
       " 'I-tim']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_classes = classes.copy()\n",
    "new_classes.pop()\n",
    "new_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1-- Epoch 1\n",
      "-- Epoch 1\n",
      "-- Epoch 1\n",
      "\n",
      "Norm: 6.16, NNZs: 32, Bias: -2.000000, T: 6700, Avg. loss: 0.001642\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 23.24, NNZs: 354, Bias: -4.000000, T: 6700, Avg. loss: 0.039104\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 24.70, NNZs: 379, Bias: -4.000000, T: 6700, Avg. loss: 0.043433\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 8.25, NNZs: 59, Bias: -4.000000, T: 6700, Avg. loss: 0.006269\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 5.29, NNZs: 20, Bias: -2.000000, T: 6700, Avg. loss: 0.001194\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 19.80, NNZs: 284, Bias: -4.000000, T: 6700, Avg. loss: 0.026866\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 17.75, NNZs: 179, Bias: -3.000000, T: 6700, Avg. loss: 0.011940\n",
      "Total training time: 0.05 seconds.\n",
      "Norm: 19.13, NNZs: 255, Bias: -4.000000, T: 6700, Avg. loss: 0.025224\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 1\n",
      "-- Epoch 1\n",
      "Norm: 7.14, NNZs: 48, Bias: -3.000000, T: 6700, Avg. loss: 0.002388\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 6.16, NNZs: 32, Bias: -2.000000, T: 6700, Avg. loss: 0.001642\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 8.77, NNZs: 74, Bias: -3.000000, T: 6700, Avg. loss: 0.006418\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 3.16, NNZs: 10, Bias: -2.000000, T: 6700, Avg. loss: 0.000149\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 8.31, NNZs: 54, Bias: -3.000000, T: 6700, Avg. loss: 0.003433\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 18.36, NNZs: 227, Bias: -3.000000, T: 6700, Avg. loss: 0.025224\n",
      "Total training time: 0.06 seconds.\n",
      "Norm: 6.08, NNZs: 37, Bias: -3.000000, T: 6700, Avg. loss: 0.002836\n",
      "Total training time: 0.05 seconds.\n",
      "Norm: 22.67, NNZs: 317, Bias: -4.000000, T: 6700, Avg. loss: 0.030299\n",
      "Total training time: 0.05 seconds.\n",
      "Norm: 23.56, NNZs: 322, Bias: 3.000000, T: 6700, Avg. loss: 0.032239\n",
      "Total training time: 0.06 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  17 | elapsed:    0.2s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  17 | elapsed:    0.3s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  17 out of  17 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
       "      fit_intercept=True, max_iter=5, n_iter=None, n_iter_no_change=5,\n",
       "      n_jobs=-1, penalty=None, random_state=0, shuffle=True, tol=None,\n",
       "      validation_fraction=0.1, verbose=10, warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per = Perceptron(verbose=10, n_jobs=-1, max_iter=5)\n",
    "per.partial_fit(X_train, y_train, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-art       0.15      0.12      0.14        24\n",
      "      B-eve       0.46      0.32      0.37        19\n",
      "      B-geo       0.42      0.91      0.57      1085\n",
      "      B-gpe       0.89      0.78      0.83       556\n",
      "      B-nat       0.11      0.25      0.15        12\n",
      "      B-org       0.55      0.35      0.43       589\n",
      "      B-per       0.72      0.43      0.53       564\n",
      "      B-tim       0.65      0.78      0.71       611\n",
      "      I-art       0.02      0.08      0.03        12\n",
      "      I-eve       0.00      0.00      0.00        18\n",
      "      I-geo       0.81      0.32      0.46       230\n",
      "      I-gpe       0.00      0.00      0.00        14\n",
      "      I-nat       0.50      0.50      0.50         2\n",
      "      I-org       0.71      0.41      0.52       445\n",
      "      I-per       0.76      0.20      0.32       591\n",
      "      I-tim       0.26      0.05      0.09       194\n",
      "\n",
      "avg / total       0.62      0.55      0.53      4966\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SusanLi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred=per.predict(X_test), y_true=y_test, labels=new_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Linear classifiers with SGD training\n",
    "\n",
    "Regularized linear models with stochastic gradient descent (SGD) learning: \n",
    "* the gradient of the loss is estimated each sample at a time\n",
    "* the model is updated along the way with a decreasing strength schedule (aka learning rate). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
       "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd = SGDClassifier()\n",
    "sgd.partial_fit(X_train, y_train, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-art       0.00      0.00      0.00         9\n",
      "       B-eve       0.00      0.00      0.00         3\n",
      "       B-geo       0.22      0.93      0.36        69\n",
      "       B-gpe       0.92      0.45      0.61       102\n",
      "       B-nat       0.00      0.00      0.00         0\n",
      "       B-org       1.00      0.05      0.09        63\n",
      "       B-per       0.94      0.41      0.58        41\n",
      "       B-tim       1.00      0.48      0.65        52\n",
      "       I-art       0.00      0.00      0.00        10\n",
      "       I-eve       0.00      0.00      0.00         3\n",
      "       I-geo       0.00      0.00      0.00        11\n",
      "       I-gpe       0.18      0.50      0.26         6\n",
      "       I-nat       0.00      0.00      0.00         1\n",
      "       I-org       0.82      0.30      0.44        47\n",
      "       I-per       0.68      0.23      0.34        66\n",
      "       I-tim       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.43      0.38      0.40       487\n",
      "   macro avg       0.36      0.21      0.21       487\n",
      "weighted avg       0.71      0.38      0.40       487\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred=sgd.predict(X_test), y_true=y_test, labels=new_classes))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
