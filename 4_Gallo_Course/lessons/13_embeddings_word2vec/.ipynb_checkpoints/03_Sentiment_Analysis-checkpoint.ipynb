{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "**Book**: Introduction to Data Science: A Python Approach to Concepts, Techniques and Applications  \n",
    "**Book**: Data Mining the textbook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Sentiment Analysis\n",
    "\n",
    "<img src=\"figures/sentiment_analysis_copy.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Sentiment analysis** or **opinion mining** analyzes  \n",
    "  * **people’s** *opinions*, *appraisals*, *attitudes*, and *emotions*  \n",
    "  * **toward** *entities*, *individuals*, *issues*, *events*, *topics*, and their attributes.\n",
    "* For **example**, businesses always want to find public or consumer **opinions about their products and services**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Social media**\n",
    "\n",
    "* **individuals and organizations** are increasingly using the content in the WEB for their **decision making**\n",
    "  * To **buy a consumer product**, there are many user **reviews of products** on the Web.\n",
    "  * To gather public **opinions about products and services** there is an abundance of information publicly available.\n",
    "* **Finding and monitoring opinion sites** on the Web and **distilling the information** contained in them remains a formidable task because of the proliferation of diverse sites. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Summarizing the information**\n",
    "\n",
    "* The average human reader will have difficulty identifying relevant sites and accurately **summarizing** the information and **opinions** contained in them.\n",
    "* **Bias problem**: `people often pay greater attention to opinions that are consistent with their own preferences`.\n",
    "* People also have difficulty, when the **amount of information** to be processed is **large**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Problem of Opinion Mining\n",
    "\n",
    "* **One opinion** represents only **the view of a single person**\n",
    "  * it is essential to **analyze a collection of opinions** rather than only one\n",
    "  * some form of **summary of opinions** is needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Problem Definitions\n",
    "We can use the review of an iPhone to introduce the problem\n",
    ">    “(1) I bought an **iPhone** a few days ago. (2) <font style=\"color:blue\">It was such a nice phone.</font> (3) <font style=\"color:blue\">The touch screen was really cool</font>. (4) <font style=\"color:blue\">The voice quality was clear too</font>. (5) <font style=\"color:red\">However, my mother was mad with me as I did not tell her before I bought it</font>. (6) <font style=\"color:red\">She also thought the phone was too expensive, and wanted me to return it to the shop</font>. ... ”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Question**: what we want to **mine or extract** from this review?\n",
    "\n",
    "* here are `several opinions` in this review.\n",
    "  * Sentences (2), (3), and (4) express some **<font style=\"color:blue\">positive opinions</font>**\n",
    "  * Sentences (5) and (6) express **<font style=\"color:red\">negative opinions</font>** or emotions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* The opinions all have some `targets`.  \n",
    "  The targets of the opinions in sentence/s   <img align=\"right\" style=\"padding-left:10px;\" src=\"figures/sentiment-graph.png\" width=\"30%\">  \n",
    "  * (2) is the **iPhone** as a whole, \n",
    "  * (3) and (4) are “ **touch screen** ” and “ **voice quality** ” of the iPhone. \n",
    "  * (6) is the **price** of the iPhone,\n",
    "  * (5) is “ **me** ”, not iPhone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Different `holder` of the opinions in sentences \n",
    "  * (2), (3), and (4) is the **author of the review** (“ I ”), \n",
    "  * (5) and (6) it is “ **my mother**. ”\n",
    "  \n",
    "With this example in mind, we can now **formally define** the `opinion mining problem`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In general, **opinions** can be **expressed about** anything, \n",
    "* e.g., a **product**, a **service**, an **individual**, an **organization**, an **event**, or a **topic**, \n",
    "* **by any person** or organization. \n",
    "\n",
    "We use the term <font style=\"color:red\">**entity**</font> to denote the **target object** that has been evaluated. \n",
    "* An entity can have a **set of components** (or parts) and a **set of attributes**. \n",
    "* Each component may have its own **sub-components** and its set of **attributes**, and so on. \n",
    "* Thus, an entity can be hierarchically decomposed based on the <font style=\"color:red\">**part-of**</font> relation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Mobile phone example**\n",
    "\n",
    "<img src=\"figures/Mobile-handset-architecture.png\" width=\"70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Definition of entity**\n",
    "\n",
    "> An **entity** $e$ is a product, service, person, event, organization, or topic.   \n",
    "  It is associated with a pair, $e$: $(T, W)$, where $T$ is a **hierarchy of components (or parts)**, subcomponents, and so on,   \n",
    "  and $W$ is a **set of attributes of e**. Each component or sub-component also has its own set of attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Example iPhone**\n",
    "\n",
    "* A particular brand of cellular phone is an entity, e.g., iPhone.\n",
    "* It has a set of **components**, e.g., *battery* and *screen*, \n",
    "* and also a set of **attributes**, e.g., *voice quality*, *size*, and *weight*. \n",
    "* The **battery component** also has its own set of **attributes**, e.g., *battery life* and *battery size*.\n",
    "\n",
    "One can express an **opinion on** \n",
    "* the **cellular phone** itself (the root node), e.g., \"<font style=\"color:red\">I do not like iPhone</font>\" or \n",
    "* on any one of its **attributes**, e.g., \"<font style=\"color:red\">The voice quality of iPhone is lousy</font>\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Simplified and Flattened entity** (two levels)\n",
    "\n",
    "* the **root level node** is still the **entity** itself, \n",
    "* the **second level nodes** are the different <font style=\"color:red\">**aspects**</font> of the entity.\n",
    "\n",
    "> The **aspects** of an entity $e$ are the **components and attributes** of $e$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Types of opinions**\n",
    "\n",
    "Two main types of opinions: \n",
    "* **Regular opinions** are often referred to simply as opinions in the research literature. \n",
    "* A **comparative opinion** expresses a relation of similarities or differences *between two or more entities*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Opinion**\n",
    "* An opinion (or regular opinion) is simply a <font style=\"color:blue\">*positive or negative view, attitude, emotion, or appraisal*</font> about an **entity** or an **aspect** of the entity from an **opinion holder**. \n",
    "\n",
    "**Opinion orientations or polarity**\n",
    "* **Positive**, **negative**, and **neutral** are called opinion orientations. \n",
    "* Neutral is often interpreted as no opinion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Definition of opinion**\n",
    "\n",
    " > An opinion (or regular opinion) is a quintuple,\n",
    "$$(e_i , a_{ij} , oo_{ijkl} , h_k , t_l )$$\n",
    "where \n",
    "* $e_i$ is the name of an **entity**, \n",
    "* $a_{ij}$ is an **aspect** of $e_i$ , \n",
    "* $oo_{ijkl}$ is the **opinion orientation**  about aspect $a_{ij}$ of entity $e_i$ , \n",
    "* $h_k$ is the **opinion holder**, and \n",
    "* $t_l$ is the **time** when the opinion is expressed by $h_k$. \n",
    "\n",
    "> The opinion orientation $oo_{ijkl}$ can be **positive**, **negative**, or **neutral** or be expressed\n",
    "with different strength/intensity levels. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Remark 1**\n",
    "\n",
    "The opinion $oo_{ijkl}$ must be \n",
    "* given by **opinion holder** $h_k$ \n",
    "* about aspect $a_{ij}$ of entity $e_i$ at time $t_l$ . \n",
    "\n",
    "Otherwise, we may **assign an opinion to a wrong entity or wrong aspect**, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Remark 2**\n",
    "\n",
    "These five components in $(e_i , a_{ij} , oo_{ijkl} , h_k , t_l )$ are essential. \n",
    "* Without any of them, it can be problematic in general.  \n",
    "  **Example** \"`The picture quality is great`\" \n",
    "  * if we do not know whose picture quality, the opinion is of little use. \n",
    "* This is not true for every application.  \n",
    "  **Examples** \n",
    "  * `knowing each opinion holder is not necessary if we want to summarize opinions from a large number of people`. \n",
    "  * New components can be added to the tuple:   \n",
    "  In some applications we may want to know the sex and age of each opinion holder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aspect-Based Opinion Summary\n",
    "\n",
    "* **One opinion** from a single holder is usually **not sufficient** for action.\n",
    "  * **Summary of opinions** is needed.\n",
    "  * A common form of summary: `aspect-based opinion summary` (or `feature-based opinion summary`)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Example of Aspect-based opinion summary**\n",
    "\n",
    "<img src=\"figures/aspect-based-opinion-summary.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Example of Aspect-based opinion summary**\n",
    "\n",
    "<img src=\"figures/visual-aspect-based-opinion-summary.png\" width=\"70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Document Sentiment Classification\n",
    "\n",
    "<img src=\"figures/docment-sentiment-classification.png\" width=\"30%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Given an **opinionated document** $d$ evaluating an entity $e$,  \n",
    "determine the opinion orientation $oo$ on $e$,  \n",
    "i.e., determine $oo$ on aspect GENERAL in the quintuple $(e, GENERAL, oo, h, t)$.  \n",
    "`e, h, and t are assumed known or irrelevant`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Assumption** \n",
    "\n",
    "Sentiment classification assumes that \n",
    "* the opinion document $d$ (e.g., a product review) expresses opinions on a **single entity** $e$ and \n",
    "* the opinions are from a **single opinion holder** $h$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Classification Based on Supervised Learning\n",
    "\n",
    "Sentiment classification obviously can be formulated as \n",
    "* a supervised learn ing problem with <font style=\"color:red\">three classes</font>, **positive**, **negative**, and **neutral**. \n",
    "* Training and testing data used in the existing research are mostly **product reviews**\n",
    "* **Example**: For Review with rating (e.g., 1–5 stars), \n",
    "  * a review with 4 or 5 stars is considered a **positive review**, \n",
    "  * a review with 1 or 2 stars is considered a **negative review** \n",
    "  * a review with 3 stars is considered a **neutral review**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Sentiment classification vs topic-based text classification**\n",
    "\n",
    "Sentiment classification is similar to classic **topic-based text classification**,   \n",
    "which classifies documents into predefined topic classes, e.g., politics, sciences, sports, etc. \n",
    "* In sentiment classification, **opinion words** (also called sentiment words) that `indicate positive or negative opinions` are important, \n",
    "  * e.g., *great, excellent, amazing, horrible, bad, worst, etc.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Supervised learning methods and features**\n",
    "\n",
    "Any existing supervised learning methods can be applied to sentiment classification, \n",
    "* e.g., **Naïve Bayesian** classification, **Support vector machines** (SVM), etc.\n",
    "\n",
    "Features\n",
    "* Unigrams, TF-IDF, Part of speech, Opinion words and phrases, Negations, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Classification Based on Unsupervised Learning\n",
    "\n",
    "**Opinion words and phrases** are the dominating indicators for sentiment classification. \n",
    "* Using **unsupervised learning** based on such words and phrases would be quite natural.\n",
    "* Perform **classification** using some **fixed syntactic phrases** that are likely to be used to **express opinions**.\n",
    "  * Example: extracts `phrases containing adjectives or adverbs` as adjectives and adverbs are good indicators of opinions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sentence Subjectivity and Sentiment Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Aspect-Based Opinion Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Mining Comparative Opinions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Opinion Spam Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Challenges and Issues \n",
    "Challenges \n",
    "* Relevant objects vs irrelevant ones \n",
    "* Same feature expressed in different wordings \n",
    "* Words that could be positive and negative in different context \n",
    "* Long text that could contain both positive and negative opinions\n",
    "* Detecting opinion oriented sentences\n",
    "* Integrating the tasks above\n",
    "\n",
    "Some other issues \n",
    "* Identifying comparison words \n",
    "* Dealing with different writing style by different people \n",
    "* Tracking changing opinions \n",
    "* Measuring strength of opinions \n",
    "* Tackling sarcastic statements and mixed views \n",
    "* Spam opinions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Python example\n",
    "\n",
    "First, let's import useful libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "#matplotlib inline \n",
    "#plt.style.use('seaborn-whitegrid')\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='times')\n",
    "plt.rc('xtick', labelsize=10) \n",
    "plt.rc('ytick', labelsize=10) \n",
    "plt.rc('font', size=12) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Installation requirements**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unidecode in /usr/local/lib/python3.5/dist-packages (1.0.23)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**download the nltk corpora**\n",
    "\n",
    "Before starting is important to download the nltk corpora. You can download individual data packages or you can download the entire collection (using “all”). Useful corpora for this notebook include wordnet, movie_reviews, and stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ignazio/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "#nltk.download()\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Task 1: Stemmer/lemmatizer example using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized_docs_no_punctuation\n",
      " [['Here', 'are', 'some', 'very', 'simple', 'basic', 'sentences'], ['They', 'wo', 'nt', 'be', 'very', 'interesting', 'I', 'm', 'afraid'], ['The', 'point', 'of', 'these', 'examples', 'is', 'to', 'learn', 'how', 'basic', 'text', 'cleaning', 'works', 'on', 'very', 'simple', 'data']]\n",
      "preprocessed_docs\n",
      " [['Here', 'are', 'some', 'very', 'simple', 'basic', 'sentence'], ['They', 'wo', 'nt', 'be', 'very', 'interesting', 'I', 'm', 'afraid'], ['The', 'point', 'of', 'these', 'example', 'is', 'to', 'learn', 'how', 'basic', 'text', 'cleaning', 'work', 'on', 'very', 'simple', 'data']]\n"
     ]
    }
   ],
   "source": [
    "raw_docs = [\"Here are some very simple basic sentences.\", \n",
    "            \"They won't be very interesting, I'm afraid.\", \n",
    "            \"The point of these examples is to _learn how basic text cleaning works_ on *very simple* data.\"\n",
    "           ]\n",
    "            \n",
    "from nltk.tokenize import word_tokenize\n",
    "tokenized_docs = [word_tokenize(doc) for doc in raw_docs]\n",
    "\n",
    "import re\n",
    "import string\n",
    "regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "tokenized_docs_no_punctuation = []\n",
    "for review in tokenized_docs:\n",
    "    new_review = []\n",
    "    for token in review:\n",
    "        new_token = regex.sub(u'', token)\n",
    "        if not new_token == u'':\n",
    "            new_review.append(new_token)\n",
    "    tokenized_docs_no_punctuation.append(new_review)\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "porter = PorterStemmer()\n",
    "snowball = SnowballStemmer('english')\n",
    "wordnet = WordNetLemmatizer()\n",
    "\n",
    "preprocessed_docs = []\n",
    "for doc in tokenized_docs_no_punctuation:\n",
    "    final_doc = []\n",
    "    for word in doc:\n",
    "        #final_doc.append(porter.stem(word))\n",
    "        # final_doc.append(snowball.stem(word))\n",
    "        # requires 'corpora/wordnet' -> nltk.download()\n",
    "        final_doc.append(wordnet.lemmatize(word))\n",
    "        # requires 'corpora/wordnet' -> nltk.download()\n",
    "    preprocessed_docs.append(final_doc)\n",
    "\n",
    "print(\"tokenized_docs_no_punctuation\\n\", tokenized_docs_no_punctuation)\n",
    "print(\"preprocessed_docs\\n\",preprocessed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Results**\n",
    "\n",
    "These examples use functions of the modules \"`PorterStemmer`\", \"`SnowballStemmer`\", and \"`WordNetLemmatizer`\". \n",
    "* Results of the three approaches are almost **equivalent**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Task 2: Word frequencies feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('Mireia', 1), ('loves', 2), ('Hector', 1), ('me', 2), ('more', 1), ('than', 1)])\n",
      "dict_items([('Mireia', 1), ('Sergio', 1), ('loves', 1), ('likes', 1), ('me', 2), ('more', 1), ('than', 1)])\n",
      "dict_items([('footbal', 1), ('basketball', 1), ('He', 1), ('likes', 1), ('more', 1), ('than', 1)])\n",
      "Our vocabulary vector is [Sergio, loves, than, likes, Mireia, Hector, basketball, He, footbal, me, more]\n",
      "The doc is \"Mireia loves me more than Hector loves me\"\n",
      "The tf vector for Document 1 is [0, 2, 1, 0, 1, 1, 0, 0, 0, 2, 1]\n",
      "The doc is \"Sergio likes me more than Mireia loves me\"\n",
      "The tf vector for Document 2 is [1, 1, 1, 1, 1, 0, 0, 0, 0, 2, 1]\n",
      "The doc is \"He likes basketball more than footbal\"\n",
      "The tf vector for Document 3 is [0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1]\n",
      "All combined, here is our master document term matrix: \n",
      "[[0, 2, 1, 0, 1, 1, 0, 0, 0, 2, 1], [1, 1, 1, 1, 1, 0, 0, 0, 0, 2, 1], [0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1]]\n"
     ]
    }
   ],
   "source": [
    "mydoclist = ['Mireia loves me more than Hector loves me', \n",
    "             'Sergio likes me more than Mireia loves me', \n",
    "             'He likes basketball more than footbal']\n",
    "from collections import Counter\n",
    "for doc in mydoclist:\n",
    "    tf = Counter()\n",
    "    for word in doc.split():\n",
    "        tf[word] +=1\n",
    "    print(tf.items())\n",
    "    \n",
    "# define a set with all possible words included\n",
    "# in all the sentences or \"corpus\"    \n",
    "def build_lexicon(corpus):  \n",
    "    lexicon = set()\n",
    "    for doc in corpus:\n",
    "        lexicon.update([word for word in doc.split()])\n",
    "    return lexicon\n",
    "def tf(term, document):\n",
    "    return freq(term, document)\n",
    "def freq(term, document):\n",
    "    return document.split().count(term)\n",
    "vocabulary = build_lexicon(mydoclist)\n",
    "doc_term_matrix = []\n",
    "print('Our vocabulary vector is [' + ', '.join(list(vocabulary)) + ']')\n",
    "for doc in mydoclist:\n",
    "    print('The doc is \"' + doc + '\"')\n",
    "    tf_vector = [tf(word, doc) for word in vocabulary]\n",
    "    tf_vector_string = ', '.join(format(freq, 'd') for freq in tf_vector)\n",
    "    print ('The tf vector for Document %d is [%s]' % ((mydoclist.index(doc)+1), tf_vector_string))\n",
    "    doc_term_matrix.append(tf_vector)\n",
    "    \n",
    "print ('All combined, here is our master document term matrix: ')\n",
    "print (doc_term_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Based on the previous script, \n",
    "* each document is in the **same feature space**,  \n",
    "* we can start applying some **machine learning** methods: classifying, clustering, and so on. \n",
    "\n",
    "**Problems**: \n",
    "* Words are **not** all **equally informative**. \n",
    "  * If words appear too frequently in a single document, they are going to muck up our analysis. \n",
    "* We need to do some **vector normalizing**: L2 norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Task 3: L2 Normalization\n",
    "\n",
    "For any given vector $\\vec{u}$ its unit vector (written as $\\hat{u}$) is calculated as follows:\n",
    "$$\\hat{u} = \\frac{\\vec{u}}{\\|\\vec{u}\\|}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A regular old document term matrix: \n",
      "[[0 2 1 0 1 1 0 0 0 2 1]\n",
      " [1 1 1 1 1 0 0 0 0 2 1]\n",
      " [0 0 1 1 0 0 1 1 1 0 1]]\n",
      "\n",
      "A document term matrix with row-wise L2 norms of 1:\n",
      "[[0.         0.57735027 0.28867513 0.         0.28867513 0.28867513\n",
      "  0.         0.         0.         0.57735027 0.28867513]\n",
      " [0.31622777 0.31622777 0.31622777 0.31622777 0.31622777 0.\n",
      "  0.         0.         0.         0.63245553 0.31622777]\n",
      " [0.         0.         0.40824829 0.40824829 0.         0.\n",
      "  0.40824829 0.40824829 0.40824829 0.         0.40824829]]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "def l2_normalizer(vec):\n",
    "    denom = np.sum([el**2 for el in vec])\n",
    "    return [(el / math.sqrt(denom)) for el in vec]\n",
    "doc_term_matrix_l2 = []\n",
    "for vec in doc_term_matrix:\n",
    "    doc_term_matrix_l2.append(l2_normalizer(vec))\n",
    "print ('A regular old document term matrix: ')\n",
    "print (np.matrix(doc_term_matrix))\n",
    "print ('\\nA document term matrix with row-wise L2 norms of 1:')\n",
    "print (np.matrix(doc_term_matrix_l2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We have scaled down the vectors so that each element is between [0, 1], without losing too much\n",
    "valuable information. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Task 4: Feature weighting by its inverse document frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our vocabulary vector is [Sergio, loves, than, likes, Mireia, Hector, basketball, He, footbal, me, more]\n",
      "The inverse document frequency vector is [1.098612, 0.405465, 0.000000, 0.405465, 0.405465, 1.098612, 1.098612, 1.098612, 1.098612, 0.405465, 0.000000]\n"
     ]
    }
   ],
   "source": [
    "def numDocsContaining(word, doclist):\n",
    "    doccount = 0\n",
    "    for doc in doclist:\n",
    "        if freq(word, doc) > 0:\n",
    "            doccount +=1\n",
    "    return doccount\n",
    "def idf(word, doclist):\n",
    "    n_samples = len(doclist)\n",
    "    df = numDocsContaining(word, doclist)\n",
    "    return np.log(n_samples / (float(df)) )\n",
    "my_idf_vector = [idf(word, mydoclist) for word in vocabulary]\n",
    "print ('Our vocabulary vector is [' + ', '.join(list(vocabulary)) + ']')\n",
    "print ('The inverse document frequency vector is [' + ', '.join(format(freq, 'f') for freq in my_idf_vector) + ']')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Task 5: Film critics binary sentiment analysis recognition code \n",
    "\n",
    "In this example we apply the whole sentiment analysis process to the Large Movie reviews\n",
    "dataset (http://www.aclweb.org/anthology/P11-1015). \n",
    "* This is one of the largest public available data sets for sentiment analysis, \n",
    "  * more than 50.000 texts from movie reviews \n",
    "  * Ground truth annotation related to **positive** and **negative** movie review. \n",
    "  * We use a subset of the dataset consisting in about 10% of the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "You can use the following commands in a Linux operating system to download the required data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-05-20 20:10:46--  http://ai.stanford.edu/~amaas//data/sentiment/aclImdb_v1.tar.gz\n",
      "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
      "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 84125825 (80M) [application/x-gzip]\n",
      "Saving to: ‘aclImdb_v1.tar.gz.1’\n",
      "\n",
      "aclImdb_v1.tar.gz.1 100%[===================>]  80,23M  3,34MB/s    in 30s     \n",
      "\n",
      "2019-05-20 20:11:17 (2,64 MB/s) - ‘aclImdb_v1.tar.gz.1’ saved [84125825/84125825]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!wget http://ai.stanford.edu/~amaas//data/sentiment/aclImdb_v1.tar.gz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘data’: File exists\n",
      "mkdir: cannot create directory ‘data/train’: File exists\n",
      "mkdir: cannot create directory ‘data/train/pos2’: File exists\n",
      "mkdir: cannot create directory ‘data/train/neg2’: File exists\n",
      "mkdir: cannot create directory ‘data/test’: File exists\n",
      "mkdir: cannot create directory ‘data/test/pos2’: File exists\n",
      "mkdir: cannot create directory ‘data/test/neg2’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir \"data\"\n",
    "!tar -xf aclImdb_v1.tar.gz -C data/\n",
    "!mkdir \"data/train\"\n",
    "!mkdir \"data/train/pos2\"\n",
    "!mkdir \"data/train/neg2\"\n",
    "!mkdir \"data/test\"\n",
    "!mkdir \"data/test/pos2\"\n",
    "!mkdir \"data/test/neg2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**For windows systems**\n",
    "\n",
    "* you can download the data here: http://ai.stanford.edu/~amaas/data/sentiment/\n",
    "* Move them to the folder data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Binary sentiment analysis recognition**\n",
    "\n",
    "Next lines of code will select a subset of the critics of the dataset to run the next example for binary sentiment analysis recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "for file in os.listdir(\"data/aclImdb/train/pos/\"):\n",
    "    if file.endswith(\".txt\"):\n",
    "        os.rename('data/aclImdb/train/pos/' + file, 'data/train/pos2/' + file)\n",
    "\n",
    "for file in os.listdir(\"data/aclImdb/train/neg/\"):\n",
    "    if file.endswith(\".txt\"):\n",
    "        os.rename('data/aclImdb/train/neg/' + file, 'data/train/neg2/' + file)\n",
    "\n",
    "for file in os.listdir(\"data/aclImdb/test/pos/\"):\n",
    "    if file.endswith(\".txt\"):\n",
    "        os.rename('data/aclImdb/test/pos/' + file, 'data/test/pos2/' + file)\n",
    "\n",
    "for file in os.listdir(\"data/aclImdb/test/neg/\"):\n",
    "    if file.endswith(\".txt\"):\n",
    "        os.rename('data/aclImdb/test/neg/' + file, 'data/test/neg2/' + file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Training and testing**\n",
    "\n",
    "And the next script will perform the whole training and testing procedure on the selected subset of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the training data positive\n",
      "Reading the training data negative\n",
      "Defining dictionaries\n",
      "Reading the test data positive\n",
      "Reading the test data negative\n",
      "Computing test feature vectors\n",
      "Training and testing on training Naive Bayes\n",
      "Number of mislabeled training points out of a total 1000 points : 12\n",
      "Training and testing on test Naive Bayes\n",
      "Number of mislabeled test points out of a total 200 points : 85\n",
      "Training and testing on train with SVM\n",
      "Number of mislabeled test points out of a total 1000 points : 188\n",
      "Testing on test with already trained SVM\n",
      "Number of mislabeled test points out of a total 200 points : 52\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm\n",
    "from unidecode import unidecode\n",
    "import time, random\n",
    "\n",
    "def BoW():\n",
    "    # Tokenizing text\n",
    "    text_tokenized = [word_tokenize(doc) for doc in text]\n",
    "    # Removing punctuation\n",
    "    regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    tokenized_docs_no_punctuation = []\n",
    "    for review in text_tokenized:\n",
    "        new_review = []\n",
    "        for token in review:\n",
    "            new_token = regex.sub(u'', token)\n",
    "            if not new_token == u'':\n",
    "                new_review.append(new_token)\n",
    "        tokenized_docs_no_punctuation.append(new_review)\n",
    "    # Stemming and Lemmatizing\n",
    "    porter = PorterStemmer()\n",
    "    preprocessed_docs = []\n",
    "    for doc in tokenized_docs_no_punctuation:\n",
    "        final_doc = ''\n",
    "        for word in doc:\n",
    "            final_doc = final_doc + ' ' + porter.stem(word)\n",
    "        preprocessed_docs.append(final_doc)\n",
    "    return preprocessed_docs\n",
    "\n",
    "print('Reading the training data positive')\n",
    "text = []\n",
    "files = random.sample(os.listdir(\"data/train/pos2/\"), 500)\n",
    "for file in files:\n",
    "    if file.endswith(\".txt\"):\n",
    "        infile = open('data/train/pos2/' + file, 'r')\n",
    "        text.append(unidecode(infile.read()))\n",
    "        infile.close()\n",
    "num_posTrain=len(text)\n",
    "\n",
    "print('Reading the training data negative')\n",
    "files = random.sample(os.listdir(\"data/train/neg2/\"), 500)\n",
    "for file in files:\n",
    "    if file.endswith(\".txt\"):\n",
    "        infile = open('data/train/neg2/' + file, 'r')\n",
    "        text.append(unidecode(infile.read()))\n",
    "        infile.close()\n",
    "num_Train=len(text)\n",
    "\n",
    "print('Defining dictionaries')\n",
    "\n",
    "preprocessed_docs=BoW()\n",
    "# Computing TIDF word space\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df = 1)\n",
    "trainData = tfidf_vectorizer.fit_transform(preprocessed_docs)\n",
    "\n",
    "# Reading the test data\n",
    "\n",
    "print('Reading the test data positive')\n",
    "\n",
    "text = []\n",
    "files = random.sample(os.listdir(\"data/test/pos2/\"), 100)\n",
    "for file in files:\n",
    "    if file.endswith(\".txt\"):\n",
    "        infile = open('data/test/pos2/' + file, 'r')\n",
    "        text.append(unidecode(infile.read()))\n",
    "        infile.close()\n",
    "num_posTest=len(text)\n",
    "\n",
    "print('Reading the test data negative')\n",
    "files = random.sample(os.listdir(\"data/test/neg2/\"), 100)\n",
    "for file in files:\n",
    "    if file.endswith(\".txt\"):\n",
    "        infile = open('data/test/neg2/' + file, 'r')\n",
    "        text.append(unidecode(infile.read()))\n",
    "        infile.close()\n",
    "num_Test=len(text)\n",
    "\n",
    "print('Computing test feature vectors')\n",
    "start_time = time.time()\n",
    "\n",
    "preprocessed_docs=BoW()\n",
    "testData = tfidf_vectorizer.transform(preprocessed_docs)\n",
    "\n",
    "targetTrain = []\n",
    "for i in range(0,num_posTrain):\n",
    "    targetTrain.append(0)\n",
    "for i in range(0,num_Train-num_posTrain):\n",
    "    targetTrain.append(1)\n",
    "\n",
    "targetTest = []\n",
    "for i in range(0,num_posTest):\n",
    "    targetTest.append(0)\n",
    "for i in range(0,num_Test-num_posTest):\n",
    "    targetTest.append(1)\n",
    "\n",
    "print('Training and testing on training Naive Bayes')\n",
    "start_time = time.time()\n",
    "\n",
    "gnb = GaussianNB()\n",
    "testData.todense()\n",
    "y_pred = gnb.fit(trainData.todense(), targetTrain).predict(trainData.todense())\n",
    "print(\"Number of mislabeled training points out of a total %d points : %d\" % (trainData.shape[0],(targetTrain != y_pred).sum()))\n",
    "\n",
    "print('Training and testing on test Naive Bayes')\n",
    "\n",
    "y_pred = gnb.fit(trainData.todense(), targetTrain).predict(testData.todense())\n",
    "print(\"Number of mislabeled test points out of a total %d points : %d\" % (testData.shape[0],(targetTest != y_pred).sum()))\n",
    "\n",
    "print('Training and testing on train with SVM')\n",
    "clf = svm.SVC(gamma=\"scale\")\n",
    "clf.fit(trainData.todense(), targetTrain)\n",
    "y_pred = clf.predict(trainData.todense())\n",
    "print(\"Number of mislabeled test points out of a total %d points : %d\" % (trainData.shape[0],(targetTrain != y_pred).sum()))\n",
    "\n",
    "print('Testing on test with already trained SVM')\n",
    "y_pred = clf.predict(testData.todense())\n",
    "print(\"Number of mislabeled test points out of a total %d points : %d\" % (testData.shape[0],(targetTest != y_pred).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The previous example uses a small percentage of one of the largest public available datasets for sentiment analysis, which includes more than 50,000 texts from movie reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example 6: Tweet binary sentiment analysis recognition code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Another **simple example** of sentiment analysis based on tweets. \n",
    "* There are more works using **more tweet data** ( http://www.sananalytics.com/lab/twitter-sentiment/ ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled training points out of a total 10 points : 0\n",
      "Training and testing on test Naive Bayes\n",
      "Number of mislabeled test points out of a total 6 points : 2\n",
      "Training and testing on train with SVM\n",
      "Number of mislabeled test points out of a total 10 points : 0\n",
      "Testing on test with already trained SVM\n",
      "Number of mislabeled test points out of a total 6 points : 2\n"
     ]
    }
   ],
   "source": [
    "def BoW():\n",
    "    # Tokenizing text\n",
    "    text_tokenized = [word_tokenize(doc) for doc in text]\n",
    "    # Removing punctuation\n",
    "    regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    tokenized_docs_no_punctuation = []\n",
    "    for review in text_tokenized:\n",
    "        new_review = []\n",
    "        for token in review:\n",
    "            new_token = regex.sub(u'', token)\n",
    "            if not new_token == u'':\n",
    "                new_review.append(new_token)\n",
    "        tokenized_docs_no_punctuation.append(new_review)\n",
    "    # Stemming and Lemmatizing\n",
    "    porter = PorterStemmer()\n",
    "    preprocessed_docs = []\n",
    "    for doc in tokenized_docs_no_punctuation:\n",
    "        final_doc = ''\n",
    "        for word in doc:\n",
    "            final_doc = final_doc + ' ' + porter.stem(word)\n",
    "        preprocessed_docs.append(final_doc)\n",
    "    return preprocessed_docs\n",
    "\n",
    "text = ['I love this sandwich.', 'This is an amazing place!',\n",
    "        'I feel very good about these beers.',\n",
    "         'This is my best work.', 'What an awesome view', 'I do not like this restaurant',\n",
    "         'I am tired of this stuff.', 'I can not deal with this', 'He is my sworn enemy!',\n",
    "         'My boss is horrible.']\n",
    "\n",
    "targetTrain = [0,0,0,0,0,1,1,1,1,1]\n",
    "preprocessed_docs=BoW()\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df = 1)\n",
    "trainData = tfidf_vectorizer.fit_transform(preprocessed_docs)\n",
    "\n",
    "text = ['The beer was good.', 'I do not enjoy my job', 'I aint feeling dandy today',\n",
    "        'I feel amazing!'\n",
    "        ,'Gary is a friend of mine.', 'I can not believe I am doing this.']\n",
    "targetTest = [0,1,1,0,0,1]\n",
    "preprocessed_docs=BoW()\n",
    "testData = tfidf_vectorizer.transform(preprocessed_docs)\n",
    "\n",
    "gnb = GaussianNB()\n",
    "testData.todense()\n",
    "y_pred = gnb.fit(trainData.todense(), targetTrain).predict(trainData.todense())\n",
    "print(\"Number of mislabeled training points out of a total %d points : %d\" % (trainData.shape[0],(targetTrain != y_pred).sum()))\n",
    "\n",
    "print('Training and testing on test Naive Bayes')\n",
    "\n",
    "y_pred = gnb.fit(trainData.todense(), targetTrain).predict(testData.todense())\n",
    "print(\"Number of mislabeled test points out of a total %d points : %d\" % (testData.shape[0],(targetTest != y_pred).sum()))\n",
    "\n",
    "print('Training and testing on train with SVM')\n",
    "clf = svm.SVC(gamma=\"scale\")\n",
    "clf.fit(trainData.todense(), targetTrain)\n",
    "y_pred = clf.predict(trainData.todense())\n",
    "print(\"Number of mislabeled test points out of a total %d points : %d\" % (trainData.shape[0],(targetTrain != y_pred).sum()))\n",
    "\n",
    "print('Testing on test with already trained SVM')\n",
    "y_pred = clf.predict(testData.todense())\n",
    "print(\"Number of mislabeled test points out of a total %d points : %d\" % (testData.shape[0],(targetTest != y_pred).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this previous simple scenario both learning strategies achieve the same recognition rates in both training and test sets.\n",
    "\n",
    "Note that similar words are shared between tweets. In practice, with real examples, tweets will include unstructured sentences and abbreviations, making recognition harder. "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
