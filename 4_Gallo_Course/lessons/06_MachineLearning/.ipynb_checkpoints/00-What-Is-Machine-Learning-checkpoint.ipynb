{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What Is Machine Learning?\n",
    "<img src=\"figures/ai-ml-deep.png\" width=\"60%\"> [image source](https://buzzrobot.com/difference-between-artificial-intelligence-machine-learning-and-deep-learning-ccfd779eca7b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Machine learning is often categorized as a **subfield of artificial intelligence**, but I find that categorization can often be misleading at first brush.\n",
    "\n",
    "The study of machine learning certainly arose from research in this context, but in the data science application of machine learning methods, it's more helpful to think of machine learning as a means of **building models of data**.\n",
    "\n",
    "<img src=\"figures/data-algorithm-model.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Fundamentally,  \n",
    "``machine learning involves building`` **mathematical models** `to help` **understand data**.\n",
    "- \"<span style=\"color:red\">Learning</span>\" means that we give these models **tunable parameters** that can be adapted to observed data; in this way the program can be considered to be **\"learning\" from the data**.\n",
    "- Once these **models** have been **fit** to previously seen **data**, they can be used to **predict** and understand aspects of newly observed data.\n",
    "- **Understanding the problem** setting in machine learning is essential to use these tools effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Machine Learning is the **science (and art) of programming computers so they can learn from data**.\n",
    "\n",
    "Here is a slightly more general **definition**:\n",
    "\n",
    "``Machine Learning is the field of study that gives computers the ability to learn without being explicitly programmed.``<br>\n",
    "*Arthur Samuel, 1959*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "And a more engineering-oriented one:\n",
    "\n",
    "``A computer program is said to learn from experience`` **E**  ``with respect to some task T and some performance measure P, if its performance on T, as measured by P, improves with experience``  <b>E</b>.  \n",
    "*Tom Mitchell, 1997*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Why Use Machine Learning?\n",
    "\n",
    "Consider how you would **write a spam filter using traditional programming techniques**:\n",
    "1.  First you would **look at what spam typically looks like**. You might notice that some words or phrases (such as “4U,” “credit card,” “free,” and “amazing”) tend to come up a lot in the subject. Perhaps you would also notice a few other patterns in the sender’s name, the email’s body, and so on.\n",
    "2.  You would **write a detection algorithm for each of the patterns that you noticed**, and your program would flag emails as spam if a number of these patterns are detected.\n",
    "3.  You would **test** your program, and **repeat** steps 1 and 2 until it is good enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img width=\"50%\" src=\"figures/ml_traditional_approach.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Since the problem is not trivial, your program will likely become a **long list of complex rules** — pretty\n",
    "**hard to maintain**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In contrast, a spam filter based on <span style=\"color:red\">Machine Learning</span> techniques **automatically learns** which words and phrases are good predictors of spam by detecting unusually frequent patterns of words in the **spam examples** compared to the **ham examples** (Figure 1-2). \n",
    "\n",
    "The program is much shorter, easier to maintain, and most likely more accurate.\n",
    "\n",
    "<img width=\"50%\" src=\"figures/machine_learning_approach.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Another area where Machine Learning shines is for **problems** that either are **too complex** for traditional\n",
    "approaches or have no known algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For ``example``, consider **speech recognition**: say you want to start simple and write a program capable of distinguishing the words “``one``” and “``two``”.\n",
    "<img align=\"right\" style=\"padding-left:10px;\" src=\"images/speech recognition.jpeg\" width=\"40%\">\n",
    "\n",
    "You might notice that the word “two” starts with a high-pitch sound (“T”), so you could **hardcode** an algorithm that measures high-pitch sound intensity and use that to distinguish ones and twos. <br>\n",
    "Obviously this technique **will not scale** to thousands of words spoken by millions of *very different people* in *noisy environments* and indozens of languages. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The **best solution** (at least today) is to write an **algorithm that learns by itself**, given many example recordings for each word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Finally, Machine Learning **can help humans learn**: \n",
    "- ML algorithms can be inspected to see what they have learned <img align=\"right\" style=\"padding-left:10px;\" width=\"50%\" src=\"figures/ml_help_to_understand.png\"> \n",
    "- For instance, once the **spam filter** has been trained on enough spam, it can easily be inspected to reveal the list of **words** and combinations of words that it believes are the best **predictors of spam**. \n",
    "- Applying ML techniques to a large amounts of data can help **discover patterns** that were not immediately apparent. \n",
    "- This is called <span style=\"color:blue;font-weight:bold\">data mining</span>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**To summarize**, Machine Learning is great for:\n",
    "* **Problems** for which existing solutions **require** a lot of **hand-tuning** or **long lists of rules**: one Machine Learning algorithm can often simplify code and perform better.\n",
    "* **Complex problems** for which **there is no good solution at all** using a traditional approach: the best Machine Learning techniques can find a solution.\n",
    "* **Fluctuating environments**: a Machine Learning system can **adapt to new data**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Categories of Machine Learning\n",
    "\n",
    "At the most fundamental level, machine learning can be categorized into two main types:  \n",
    "**supervised** learning and  \n",
    "**unsupervised** learning.\n",
    "\n",
    "<img src=\"figures/WHAT-IS-MACHINE-LEARNING.svg\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Supervised learning** involves somehow modeling the relationship between \n",
    "- measured **features** of data  \n",
    "- some **label** associated with the data \n",
    "\n",
    "Once this model is determined, it can be used to **apply labels to new, unknown data**.  \n",
    "This is further subdivided into \n",
    "- **classification** tasks: the labels are discrete categories \n",
    "- **regression** tasks: the labels are continuous quantities. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Unsupervised learning** involves modeling the **features** of a dataset without reference to **any label**.\n",
    "\n",
    "These models include tasks such as \n",
    "- **clustering**: identify distinct groups of data;\n",
    "- **dimensionality reduction**: search for more succinct representations of the data;\n",
    "- **association rule learning**: discover sales correlations in transactional data or in medical data sets.\n",
    "\n",
    "In addition, there are so-called **semi-supervised learning** methods, which falls somewhere between supervised learning and unsupervised learning.<br>Semi-supervised learning methods are often useful when only incomplete labels are available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Other categories of machine learning algorithms are:\n",
    "\n",
    "* **online** versus **batch** learning:  \n",
    "  whether or not they can learn incrementally on the fly\n",
    "\n",
    "* **instance-based** versus **model-based** learning:  \n",
    "  * Whether they work by simply comparing new data points to known data points (e.g. **KNN**-algorithm), \n",
    "  * detect patterns in the training data and build a predictive model (like **Logistic**, **Decision tree** etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Qualitative Examples of Machine Learning Applications\n",
    "\n",
    "To make these ideas more concrete, let's take a look at a few very simple examples of a machine learning task.<br>\n",
    "These examples are meant to give an intuitive, **non-quantitative overview** of the types of machine learning tasks we will be looking at in this chapter.<br>\n",
    "In later sections, we will go into more depth regarding the particular models and how they are used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Classification: Predicting discrete labels\n",
    "\n",
    "We will first take a look at a simple *classification* task, in which you are given a set of labeled points and want to use these to classify some unlabeled points.\n",
    "\n",
    "Imagine that we have the data shown in this figure:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figures/05.01-classification-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Here we have **two-dimensional data**: that is, \n",
    "* we have two **features** for each point, represented by the **(x,y)** positions of the points on the plane.\n",
    "* In addition, we have one of two **class labels** for each point, here represented by the colors of the points.\n",
    "\n",
    "``From these features and labels, we would like to create a model that will let us decide whether a new point should be labeled \"blue\" or \"red.\"``\n",
    "\n",
    "There are a number of possible models for such a classification task, but here we will use an extremely simple one.  \n",
    "We will make the assumption that the **model** is a quantitative version of the statement \"``a straight line separates the classes``\", while the **model parameters** are the particular numbers describing the ``location and orientation of that line`` for our data.\n",
    "\n",
    "The optimal values for these model parameters are learned from the data (this is the \"learning\" in machine learning), which is often called *training the model*.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The following figure shows a visual representation of what the **trained model** looks like for this data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "![](figures/05.01-classification-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now that this model has been trained, it can be ``generalized to new, unlabeled data``.\n",
    "* we can take a **new set of data**, draw this model line through it, and assign labels to the new points based on this model.\n",
    "* This stage is usually called **prediction**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](figures/05.01-classification-3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* This is the basic idea of a classification task in machine learning, where \"classification\" indicates that the **data has discrete class labels**.\n",
    "* At first glance this may look fairly trivial: it would be relatively easy to simply look at this data and draw such a discriminatory line to accomplish this classification.\n",
    "* A benefit of the machine learning approach, however, is that it **can generalize** to much larger datasets in many more dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For example, this is similar to the task of **automated spam detection for email**; in this case, we might use the following features and labels: \n",
    "- *feature 1*, *feature 2*, etc. $\\to$ normalized counts <img align=\"right\" style=\"padding-left:10px;\" src=\"figures/spam-labeled-training-set.png\" width=\"50%\"> of important words or phrases (\"Viagra\", \"Nigerian prince\", etc.)  \n",
    "- *label* $\\to$ \"spam\" or \"not spam\"\n",
    "\n",
    "For the **training set**, these labels might be determined by individual inspection of a small representative sample of emails;  \n",
    "for the remaining emails, the **label** would be **determined using the model**.\n",
    "\n",
    "Some important classification algorithms that we will discuss are for example **decision tree**, **random forest**, etc.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Regression: Predicting continuous labels\n",
    "\n",
    "In contrast with the discrete labels of a classification algorithm, we will next look at a simple **regression** task in which the **labels are continuous quantities**.\n",
    "\n",
    "A typical task is to ``predict a target numeric value``, such as **the price of a car**, given a set of features (mileage, age, brand, etc.) called predictors.  <img align=\"right\" style=\"padding-left:10px;\" src=\"figures/regression-1D-example.png\" width=\"50%\">\n",
    "To train the system, you need to give it many examples of cars, including both their predictors and their labels (i.e., their prices)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Consider the data shown in the following figure, which consists of a set of points each with a **continuous label**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](figures/05.01-regression-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "As with the classification example, we have **two-dimensional data**: that is, \n",
    "* there are **two features** describing each data point.\n",
    "* The color of each point represents the **continuous label** for that point.\n",
    "\n",
    "There are a number of possible regression models we might use for this type of data, but here we will use a simple **linear regression** to predict the points.  \n",
    "This simple linear regression model assumes that if we treat the **label as a third spatial dimension**, we can fit a plane to the data.  \n",
    "This is a higher-level generalization of the well-known problem of fitting a line to data with two coordinates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can visualize this setup as shown in the following figure:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<img src=\"figures/05.01-regression-2.png\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Notice that the *feature 1-feature 2* plane here is the same as in the two-dimensional plot from before; in this case, however, we have represented the **labels by both color and three-dimensional axis position**.\n",
    "\n",
    "From this view, it seems reasonable that fitting a plane through this three-dimensional data would allow us to **predict the expected label for any set of input parameters**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Returning to the two-dimensional projection, when we fit such a plane we get the **result** shown in the following figure:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "![](figures/05.01-regression-3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This plane of fit gives us what we need to **predict labels** for **new points**.  \n",
    "Visually, we find the results shown in the following figure:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](figures/05.01-regression-4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "These methods can be straightforwardly **applied** and evaluated in the case of data with many, **many features**.\n",
    "\n",
    "For example, this is similar to the task of **computing the distance to galaxies observed through a telescope**—in this case, we might use the following features and labels:\n",
    "- *feature 1*, *feature 2*, etc. $\\to$ **brightness** of each galaxy at one of several wave lengths or colors\n",
    "- *label* $\\to$ **distance** or redshift of the galaxy\n",
    "\n",
    "The distances for a small number of these galaxies might be determined through an independent set of (typically more expensive) observations.\n",
    "Distances to remaining galaxies could then be estimated using a suitable regression model, without the need to employ the more expensive observation across the entire set.\n",
    "In astronomy circles, this is known as the \"photometric redshift\" problem.\n",
    "\n",
    "Some important regression algorithms that we will discuss are for example  \n",
    "**linear regression**, **random forest regression**, etc.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Clustering: Inferring labels on unlabeled data\n",
    "\n",
    "The classification and regression illustrations we just looked at are examples of supervised learning algorithms, in which we are trying to build a model that will predict labels for new data.  \n",
    "**Unsupervised learning** involves models that describe data without reference to ``any known labels``.\n",
    "\n",
    "One common case of unsupervised learning is \"**clustering**\", in which ``data is automatically assigned to some number of discrete groups``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For example, we might have some two-dimensional data like that shown in the following figure:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "![](figures/05.01-clustering-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "By eye, it is clear that **each** of these **points** is part of a **distinct group**.\n",
    "\n",
    "Given this input, a clustering model will use the intrinsic structure of the data to determine which points are related."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Using the very fast and intuitive **k-means** algorithm, we find the clusters shown in the following figure:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<img src=\"figures/05.01-clustering-2.png\" width=\"40%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**k-means** fits a model consisting of **k cluster centers**; \n",
    "\n",
    "the optimal centers are assumed to be those that minimize the distance of each point from its assigned center.\n",
    "\n",
    "Again, this might seem like a trivial exercise in two dimensions, but as our data becomes larger and more complex, such clustering algorithms can be employed to extract useful information from the dataset.\n",
    "\n",
    "Other important clustering algorithms include **Gaussian mixture** models and **spectral clustering**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Dimensionality reduction: Inferring structure of unlabeled data\n",
    "\n",
    "Dimensionality reduction is another example of an **unsupervised algorithm**, in which labels or other information are inferred from the structure of the dataset itself.\n",
    "\n",
    "Dimensionality reduction is a bit more abstract than the examples we looked at before, but generally it ``seeks to pull out some low-dimensional representation of data that in some way preserves relevant qualities of the full dataset``.\n",
    "Different dimensionality reduction routines measure these relevant qualities in different ways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "As an example of this, consider the data shown in the following figure:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "![](figures/05.01-dimesionality-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Visually, it is clear that there is some structure in this data: it is drawn from a **one-dimensional line** that is arranged **in a spiral** within this two-dimensional space.\n",
    "In a sense, you could say that this data is \"intrinsically\" only one dimensional, though this one-dimensional data is embedded in higher-dimensional space.\n",
    "A suitable dimensionality reduction model in this case would be sensitive to this nonlinear embedded structure, and be able to pull out this lower-dimensionality representation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following figure shows a visualization of the results of the **Isomap algorithm**, a manifold learning algorithm that does exactly this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](figures/05.01-dimesionality-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Notice that the colors (which represent the extracted one-dimensional latent variable) change uniformly along the spiral, which indicates that the algorithm did in fact detect the structure we saw by eye.\n",
    "As with the previous examples, the power of dimensionality reduction algorithms becomes clearer in higher-dimensional cases.\n",
    "For example, we might wish to visualize important relationships within a dataset that has 100 or 1,000 features.\n",
    "Visualizing 1,000-dimensional data is a challenge, and one way we can make this more manageable is to use a dimensionality reduction technique to reduce the data to two or three dimensions.\n",
    "\n",
    "Some important dimensionality reduction algorithms are **principal component analysis (PCA)** and various manifold learning algorithms, including **Isomap** and **locally linear embedding**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary\n",
    "\n",
    "Here we have seen a few simple examples of some of the basic types of machine learning approaches.\n",
    "\n",
    "In short, we saw the following:\n",
    "\n",
    "- *Supervised learning*: Models that can predict labels based on labeled training data\n",
    "\n",
    "  - *Classification*: Models that predict labels as two or more discrete categories\n",
    "  - *Regression*: Models that predict continuous labels\n",
    "  \n",
    "- *Unsupervised learning*: Models that identify structure in unlabeled data\n",
    "\n",
    "  - *Clustering*: Models that detect and identify distinct groups in the data\n",
    "  - *Dimensionality reduction*: identify lower-dimensional structure in higher-dimensional data"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
