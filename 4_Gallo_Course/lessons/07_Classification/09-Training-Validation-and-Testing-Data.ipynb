{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Training and Testing Data\n",
    "To evaluate how well our supervised models generalize, we can **split** our data into a training and a test set:\n",
    "\n",
    "<img src=\"figures/train_test_split.svg\" width=\"100%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **test data** is a **simulation** of \"**future data**\" which will come into the system during production. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shuffle before splitting\n",
    "For iris, the labels in iris are sorted, which means that if we split the data using a proportional split, we will get all of specific labels (0 and 1) and very little of another (2). \n",
    "\n",
    "We want to split as illustrated above, but *after* the data has been **randomly shuffled**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "classifier = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To get an accurate simulation of the real world, we will **shuffle** our data **then split**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 0 2 0 2 0 1 1 1 2 1 1 1 1 0 1 1 0 0 2 1 0 0 2 0 0 1 1 0 2 1 0 2 2 1 0\n",
      " 1 1 1 2 0 2 0 0 1 2 2 2 2 1 2 1 1 2 2 2 2 1 2 1 0 2 1 1 1 1 2 0 0 2 1 0 0\n",
      " 1 0 2 1 0 1 2 1 0 2 2 2 2 0 0 2 2 0 2 0 2 2 0 0 2 0 0 0 1 2 2 0 0 0 1 1 0\n",
      " 0 1 0 2 1 2 1 0 2 0 2 0 0 2 0 2 1 1 1 2 2 1 1 0 1 2 2 0 1 1 1 1 0 0 0 2 1\n",
      " 2 0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "rng = np.random.RandomState(0)\n",
    "\n",
    "permutation = rng.permutation(len(X))\n",
    "X, y = X[permutation], y[permutation]\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now we need to ``split`` the data into **training** and **testing**. <br>\n",
    "Luckily, this is a common pattern in machine learning and scikit-learn has a prebuilt function to split data into training and testing for you. <br>\n",
    "Here we use 50% of the data as training, and 50% testing. <br>\n",
    "80% and 20% is another common split, but there are no hard and fast rules. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels for training and testing data\n",
      "[0 1 1 2 2 2 0 2 2 1 1 2 2 1 1 1 1 1 0 2 2 2 1 0 2 1 1 2 1 0 2 2 0 2 2 0 2\n",
      " 1 0 2 0 2 2 2 0 2 0 0 1 0 1 0 2 1 1 0 1 2 1 0 0 0 1 0 1 0 1 0 0 0 0 0 1 1\n",
      " 2]\n",
      "[1 0 1 2 2 1 1 0 1 0 0 2 2 2 1 0 2 0 2 1 0 0 0 2 1 1 1 1 1 0 2 2 2 2 0 1 0\n",
      " 1 2 1 2 2 1 2 2 1 0 2 0 2 1 2 0 0 2 0 2 1 2 1 0 1 0 1 0 2 2 0 0 0 1 0 1 0\n",
      " 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.5, random_state=1999)\n",
    "print(\"Labels for training and testing data\")\n",
    "print(train_y)\n",
    "print(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Never use test set for training!\n",
    "The most important thing is to fairly **evaluate** your system on data it **has not seen during training**!\n",
    "\n",
    "By evaluating our classifier performance on data that has been seen during training, we could get **false confidence** in the power of our system. \n",
    "\n",
    "This might lead to putting a system into production which *fails* at predicting new data!   \n",
    "It is much better to use a train/test split in order to properly see how your trained model is doing on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction Correct\n",
      "0.96\n"
     ]
    }
   ],
   "source": [
    "classifier.fit(train_X, train_y)\n",
    "pred_y = classifier.predict(test_X)\n",
    "print(\"Fraction Correct\")\n",
    "print(np.sum(pred_y == test_y) / float(len(test_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Visualization\n",
    "We can also **visualize** the **correct** and **failed** predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 39 40 41 42 43 44 45 46 47 48 49\n",
      " 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 73 74]\n",
      "incorrect [24 38 72]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "correct_idx = np.where(pred_y == test_y)[0]\n",
    "print(\"correct\", correct_idx)\n",
    "\n",
    "incorrect_idx = np.where(pred_y != test_y)[0]\n",
    "print(\"incorrect\", incorrect_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot two dimensions\n",
    "colors = [\"darkblue\", \"darkgreen\", \"gray\"]\n",
    "for n, color in enumerate(colors):\n",
    "    idx = np.where(test_y == n)[0]\n",
    "    plt.scatter(test_X[idx, 0], test_X[idx, 1], color=color, label=\"Class %s\" % str(n))\n",
    "    \n",
    "plt.scatter(test_X[incorrect_idx, 0], test_X[incorrect_idx, 1], color=\"darkred\")\n",
    "\n",
    "# Make xlim larger to accommodate legend\n",
    "plt.xlim(3, 9)\n",
    "plt.legend(loc=3)\n",
    "plt.title(\"Iris Classification results\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can see that the **errors occur in the area where green** (class 1) **and gray** (class 2) **overlap**. \n",
    "\n",
    "This gives us insight about what **features to add** - any feature which helps separate class 1 and class 2 should improve classifier performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##  Split a dataset in Train and Test using Numpy\n",
    "\n",
    "If we want to split the Iris dataset in two subset, we can use ``numpy.random.permutation`` because we need to **keep track of the indices**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_y: [0 1 2 0 0 2 2 2 2 2 2 2 2 0 1 2 2 1 2 0 2 2 1 1 2 0 0 2 0 2 1 2 2 1 0 1 2\n",
      " 0 1 1 0 0 0 1 2 1 1 0 0 1 0 2 2 2 1 0 1 1 1 1 2 0 0 2 0 1 2 2 1 2 1 1 0 1\n",
      " 0 0 2 1 0 0 1 0 0 2 0 1 0 2 1 1 2 1 1 0 2 0 0 1 2 0 2 0 0 2 1 0 0 2 1 0 0\n",
      " 2 2 2 0 2 0 1 1 0]\n",
      "Test_y: [2 1 2 0 0 1 1 0 1 1 1 2 2 1 0 1 1 1 0 2 2 2 0 0 1 1 1 1 2 0]\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from random import shuffle\n",
    "\n",
    "# We can use NumPy's array indexing:\n",
    "assert len(X) == len(y)\n",
    "p = numpy.random.permutation(len(X))\n",
    "# print(\"indices:\",p)\n",
    "\n",
    "# This will result in creation of separate unison-shuffled arrays.\n",
    "X1 = X[p] \n",
    "y1 = y[p]\n",
    "# print(\"y: \",y)\n",
    "# print(\"y1:\",y1)\n",
    "\n",
    "# Here is a way to split the data into two sets: 80% train, 20% test.\n",
    "split = int(0.8 * len(X))\n",
    "train_X = X1[:split]\n",
    "train_y = y1[:split]\n",
    "\n",
    "test_X = X1[split:]\n",
    "test_y = y1[split:]\n",
    "print(\"Train_y:\", train_y)\n",
    "print(\"Test_y:\", test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Using k-fold cross-validation to assess model performance\n",
    "\n",
    "source: [python-machine-learning-book](https://github.com/rasbt/python-machine-learning-book)\n",
    "\n",
    "One of the key steps in building a machine learning model is to ``estimate its performance on data that the model hasn't seen before``.<br>\n",
    "A model can either suffer from **underfitting** if the model is too simple, or it can **overfit** training data  if the model is too complex for the underlying training data. <br>\n",
    "To find an acceptable trade-off, we need to evaluate our model carefully. \n",
    "\n",
    "In this section, you will learn about the useful ``cross-validation techniques`` \n",
    "* **holdout cross-validation** and \n",
    "* **k-fold cross-validation**, \n",
    "\n",
    "which can help us to obtain reliable estimates of the model's generalization error, that is, ``how well the model performs on unseen data``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The holdout method\n",
    "\n",
    "A classic and popular approach for ``estimating the generalization performance`` of machine learning models is **holdout cross-validation**. <br>\n",
    "We split our initial dataset into  \n",
    "* **training** dataset: used for model training \n",
    "* **test** dataset: used to estimate the model performance. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### model selection: tuning hyperparameters\n",
    "\n",
    "However, in typical machine learning applications, we are also interested in  \n",
    "``tuning and comparing different parameter settings``   \n",
    "to further improve the performance for making predictions on unseen data. \n",
    "\n",
    "This process is called **model selection**, where the term model selection refers to a given classification problem for which we want to select the optimal values of **tuning parameters** (also called **hyperparameters**).\n",
    "\n",
    "However, if we ``reuse the same test dataset`` over and over again during model\n",
    "selection, it will become part of our training data and thus the model will be more\n",
    "likely to **overfit**. <br>\n",
    "Despite this issue, many people still ``use the test set for model selection``, which ``is not a good machine learning practice``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A better way of using the holdout method for model selection is to separate the data\n",
    "into three parts: <br>\n",
    "* a **training set**, used to fit the different models\n",
    "* a **validation set**, used for the model selection \n",
    "* a **test set**., that the model hasn't seen before during the training and model selection steps\n",
    "\n",
    "\n",
    "<img src=\"./figures/06_02.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "How could we split randomly a data set and the corresponding label vector into a ``X_train``, ``X_test``, ``X_val``, ``y_train``, ``y_test``, ``y_val`` with Sklearn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# We can use sklearn.model_selection.train_test_split twice. \n",
    "# First to split to train, test \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# and then split train again into validation and train\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=1)\n",
    "print(\"Labels for training, validation and testing data\")\n",
    "print(\"TRAIN:\",y_train)\n",
    "print(\"TEST:\",y_test)\n",
    "print(\"VAL:\",y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## K-fold cross-validation\n",
    "\n",
    "In $k$-fold cross-validation, we ``randomly split`` the training dataset into $k$ folds ``without replacement``, where $k âˆ’ 1$ folds are used for the model **training** and one fold is used for **testing**. <br>\n",
    "This procedure is repeated $k$ times so that we obtain $k$ models and performance estimates.\n",
    "\n",
    "<img src=\"./figures/06_03.png\" width=\"70%\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [ 12  13  14  16  17  19  21  22  23  24  25  26  27  28  29  30  31  32\n",
      "  33  34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50\n",
      "  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68\n",
      "  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86\n",
      "  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104\n",
      " 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122\n",
      " 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140\n",
      " 141 142 143 144 145 146 147 148 149] TEST: [ 0  1  2  3  4  5  6  7  8  9 10 11 15 18 20]\n",
      "Fold: 0, Acc: 1.000\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   8   9  10  11  15  18  20  21  27  28\n",
      "  29  31  32  35  36  37  38  39  41  42  43  44  45  46  47  48  49  50\n",
      "  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68\n",
      "  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86\n",
      "  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104\n",
      " 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122\n",
      " 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140\n",
      " 141 142 143 144 145 146 147 148 149] TEST: [12 13 14 16 17 19 22 23 24 25 26 30 33 34 40]\n",
      "Fold: 1, Acc: 1.000\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  22  23  24  25  26  30  33  34  37  38  39  40  44  45  50\n",
      "  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68\n",
      "  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86\n",
      "  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104\n",
      " 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122\n",
      " 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140\n",
      " 141 142 143 144 145 146 147 148 149] TEST: [21 27 28 29 31 32 35 36 41 42 43 46 47 48 49]\n",
      "Fold: 2, Acc: 0.933\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  40  41  42  43  46  47  48  49  52  53  58  59  60  62  63  64  65\n",
      "  66  67  70  71  73  74  75  76  77  78  79  80  81  82  83  84  85  86\n",
      "  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104\n",
      " 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122\n",
      " 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140\n",
      " 141 142 143 144 145 146 147 148 149] TEST: [37 38 39 44 45 50 51 54 55 56 57 61 68 69 72]\n",
      "Fold: 3, Acc: 0.867\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  54  55\n",
      "  56  57  61  64  65  66  68  69  71  72  74  77  79  80  81  83  84  85\n",
      "  86  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104\n",
      " 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122\n",
      " 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140\n",
      " 141 142 143 144 145 146 147 148 149] TEST: [52 53 58 59 60 62 63 67 70 73 75 76 78 82 87]\n",
      "Fold: 4, Acc: 1.000\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  67  68  69  70  72  73  75  76\n",
      "  77  78  79  81  82  87  89  90  92  94  95  98  99 100 101 102 103 104\n",
      " 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122\n",
      " 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140\n",
      " 141 142 143 144 145 146 147 148 149] TEST: [64 65 66 71 74 80 83 84 85 86 88 91 93 96 97]\n",
      "Fold: 5, Acc: 1.000\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  78  80  82  83  84  85  86  87  88  91  93  96  97\n",
      "  98 103 104 107 109 110 111 112 113 114 115 116 117 118 119 120 121 122\n",
      " 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140\n",
      " 141 142 143 144 145 146 147 148 149] TEST: [ 77  79  81  89  90  92  94  95  99 100 101 102 105 106 108]\n",
      "Fold: 6, Acc: 1.000\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  99 100 101 102 105 106 108 119 120 121\n",
      " 122 123 124 125 126 128 129 130 131 132 133 134 135 136 137 138 139 140\n",
      " 141 142 143 144 145 146 147 148 149] TEST: [ 98 103 104 107 109 110 111 112 113 114 115 116 117 118 127]\n",
      "Fold: 7, Acc: 1.000\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 127 131 136 137 138 139 140\n",
      " 141 142 143 144 145 146 147 148 149] TEST: [119 120 121 122 123 124 125 126 128 129 130 132 133 134 135]\n",
      "Fold: 8, Acc: 0.933\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 132 133 134 135] TEST: [131 136 137 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "Fold: 9, Acc: 0.933\n",
      "\n",
      "CV accuracy: 0.967 +/- 0.045\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, random_state=1, shuffle=False)  \n",
    "classifier = KNeighborsClassifier()\n",
    "scores = []\n",
    "for k, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    classifier.fit(X_train, y_train)\n",
    "    pred_y = classifier.predict(X_test)\n",
    "    score = np.sum(pred_y == y_test) / float(len(y_test))\n",
    "    scores.append(score)\n",
    "    print('Fold: %s, Acc: %.3f' % (k, score))\n",
    "    \n",
    "print('\\nCV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
