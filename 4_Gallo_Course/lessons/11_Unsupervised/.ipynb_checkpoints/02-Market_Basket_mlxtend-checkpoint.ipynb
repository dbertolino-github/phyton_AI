{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Market Basket Analysis Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The python implementation in `MLxtend` should be very familiar to anyone that has exposure to scikit-learn and pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This analysis requires that **all the data** for a transaction be included in **1 row** and the items should be **1-hot encoded**.\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/mlxtend-ass-rule-data.png\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The specific data for this article comes from the UCI Machine Learning Repository and   \n",
    "represents **transactional data from a UK retailer from 2010-2011**. \n",
    "\n",
    "This mostly represents sales to wholesalers so it is slightly different from consumer purchase patterns but is still a useful case study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_excel('http://archive.ics.uci.edu/ml/machine-learning-databases/00352/Online%20Retail.xlsx')\n",
    "df = pd.read_excel('data/Online-Retail.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up spaces in description and remove any rows that don't have a valid invoice\n",
    "df['Description'] = df['Description'].str.strip()\n",
    "df.dropna(axis=0, subset=['InvoiceNo'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['InvoiceNo'] = df['InvoiceNo'].astype('str')\n",
    "df = df[~df['InvoiceNo'].str.contains('C')]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the cleanup, we need to consolidate the items into **1 transaction per row** with each **product 1 hot encoded**. \n",
    "\n",
    "For the sake of keeping the data set small, I’m only looking at sales for **France**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basket = (df[df['Country'] ==\"France\"]\n",
    "          .groupby(['InvoiceNo', 'Description'])['Quantity']\n",
    "          .sum().unstack().reset_index().fillna(0)\n",
    "          .set_index('InvoiceNo'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basket.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show a subset of columns\n",
    "basket.iloc[:,[0,1,2,3,4,5,6, 7]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of zeros in the data but we also need to make sure \n",
    "* any positive values are converted to a 1 and \n",
    "* anything less the 0 is set to 0. \n",
    "\n",
    "This step will complete the one hot encoding of the data and remove the postage column (since that charge is not one we wish to explore):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the units to 1 hot encoded values\n",
    "def encode_units(x):\n",
    "    if x <= 0:\n",
    "        return 0\n",
    "    if x >= 1:\n",
    "        return 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basket_sets = basket.applymap(encode_units)\n",
    "basket_sets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No need to track postage\n",
    "basket_sets.drop('POSTAGE', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "basket_sets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data is structured properly, we can generate **frequent item sets** that have a support of at least 7% (this number was chosen so that we could get enough useful examples):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build up the frequent items\n",
    "frequent_itemsets = apriori(basket_sets, min_support=0.07, use_colnames=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "frequent_itemsets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step is to **generate the rules** with their corresponding **support**, **confidence** and **lift**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create the rules\n",
    "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1)\n",
    "rules.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## That’s all! \n",
    "* Build the **frequent items** using apriori then \n",
    "* build the **rules** with association_rules ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figuring out what this tells us\n",
    "* We can see that there are quite a few **rules with a high lift** value which means that `it occurs more frequently than would be expected` given the number of transaction and product combinations. \n",
    "* We can also see several where the **confidence** is **high** as well. \n",
    "\n",
    "We can **filter** the dataframe using standard pandas code.  \n",
    "In this case, **look for a large lift (6) and high confidence (.8)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rules[ (rules['lift'] >= 6) &\n",
    "       (rules['confidence'] >= 0.8) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In looking at the rules, it seems that \n",
    "1. the green and red alarm clocks are purchased together \n",
    "2. the red paper cups, napkins and plates are purchased together in a manner that is higher than the overall probability would suggest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendations\n",
    "At this point, you may want to look at how much opportunity there is to **use the popularity of one product** to **drive sales of another**. \n",
    "\n",
    "For instance, we can see that `we sell 340 Green Alarm clocks but only 316 Red Alarm Clocks` so maybe we can drive more Red Alarm Clock sales through **recommendations**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basket['ALARM CLOCK BAKELIKE GREEN'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "basket['ALARM CLOCK BAKELIKE RED'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change the country of purchase\n",
    "What is also interesting is to see `how the combinations vary by country of purchase`. \n",
    "\n",
    "Let’s check out what some popular combinations might be in Germany:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basket2 = (df[df['Country'] ==\"Germany\"]\n",
    "          .groupby(['InvoiceNo', 'Description'])['Quantity']\n",
    "          .sum().unstack().reset_index().fillna(0)\n",
    "          .set_index('InvoiceNo'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basket_sets2 = basket2.applymap(encode_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basket_sets2.drop('POSTAGE', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_itemsets2 = apriori(basket_sets2, min_support=0.05, use_colnames=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules2 = association_rules(frequent_itemsets2, metric=\"lift\", min_threshold=1)\n",
    "rules2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rules2[ (rules2['lift'] >= 4) &\n",
    "        (rules2['confidence'] >= 0.5) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that **Germans** love `Plasters in Tin Spaceboy` and `Woodland Animals`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "## Practice \n",
    "1. Find out what are the popular combinations for Italians using `Online-Retail.xlsx` dataset\n",
    "2. Check out what some popular association rules might be using `order_products__prior-100000.csv` dataset\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here:\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
