{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Mining Frequent Itemsets\n",
    "\n",
    "* Association rule mining: Proposed by **Agrawal et al in 1993**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* It is an important data mining model  \n",
    "  studied extensively by the database and **data mining** community. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Assume all data are **categorical**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **No** good algorithm for **numeric data**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Initially used for **Market Basket Analysis** to find how items purchased by customers are related."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Market-Basket Model\n",
    "\n",
    "Is one of the key techniques used by **large retailers** to **uncover associations between items**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* A large set of <font color=\"red\">**items**</font> $I=\\{i_1, i_2,\\dots,i_m\\}$: e.g things sold in a supermarket."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* A large set of <font color=\"red\">**baskets**</font> or transaction $T = \\{t_1, t_2, …, t_n\\}$, each of which is a **small set** of items $t_i \\subseteq I$: e.g. the things one customer buys on one day.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "It allows retailers to `identify relationships between the items that people buy`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Transaction data: supermarket data\n",
    "\n",
    "* Market basket transactions:\n",
    "\t   t1: {bread, cheese, milk}\n",
    "\t   t2: {apple, eggs, salt, yogurt}\n",
    "\t    … \t\t…\n",
    "\t   tn: {biscuit, eggs, milk}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Concepts:\n",
    "  * An <font color=\"red\"> item</font>:  an item/article in a basket\n",
    "  * Set <font color=\"red\">I</font>: the set of all items sold in the store\n",
    "  * A <font color=\"red\">transaction</font>: items purchased in a basket; it may have TID (transaction ID)\n",
    "  * A <font color=\"red\">transactional dataset</font>: A set of transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Support\n",
    "\n",
    "* **Simplest question**: find sets of items that appear \"`frequently`\" in the baskets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* <font color=\"red\">Support</font> for itemset $I_i$ = the number of baskets containing all items in $I_i$.\n",
    "  * Sometimes given as a percentage.\n",
    "  $$\\text{support}(I_i)=\\frac{\\text{number of baskets containing}~ I_i}{\\text{total number of basket}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* <font color=\"red\">Support threshold</font> $s$: sets of items that appear in at least $s$ baskets (or transactions)  \n",
    "(called <font color=\"red\">frequent itemsets</font>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Simple example of frequent Itemset\n",
    "\n",
    "* items = {milk, coke, pepsi, beer, juice}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* support threshold = 3 baskets (sets of items that appear in at least 3 baskets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\\begin{matrix}\n",
    " B_1 = \\{m, c, b\\} & B_2 = \\{m, p, j\\}  \\\\ \n",
    " B_3 = \\{m, b\\} & B_4 = \\{c, j\\}  \\\\ \n",
    " B_5 = \\{m, p, b\\} & B_6 = \\{m, c, b, j\\} \\\\\n",
    " B_7 = \\{c, b, j\\} & B_8 = \\{b, j\\} \n",
    "\\end{matrix}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Frequent itemsets: $\\{m\\}$, $\\{c\\}$, $\\{b\\}$, $\\{j\\}$, $\\{m, b\\}$, $\\{b, c\\}$, $\\{c, j\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Applications\n",
    "\n",
    "*  <font color=\"red\">Items</font> = products.  \n",
    "   <font color=\"red\">Baskets</font> = sets of products someone bought in one trip to the store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **Example application**: given that many people buy beer and diapers together:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  * Run a sale on diapers; raise price of beer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Only useful if many buy diapers & beer.  \n",
    "  *  Essential for phisical stores, not on-line store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Applications (2)\n",
    "\n",
    "*  <font color=\"red\">Baskets</font> = documents.  \n",
    "   <font color=\"red\">Items</font> = words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* `Unusual words appearing together in a large number of documents`, e.g. \"Brad\" and \"Angelina\", may indicate an interesting relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Brute Force Algorithms\n",
    "\n",
    "* For a universe of **items** $U$, there are a total of $2^{|U|} − 1$ distinct subsets, excluding the\n",
    "empty set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* One possibility for `Frequent Itemset Mining` would be to **generate all** these candidate itemsets,  \n",
    "  and count their **support** against the transaction database $T$ (all the baskets)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* These candidates need to be **verified** against the transaction database **by support counting**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* **Support of an itemset**: count itemset $I$ that is subset of transactions $t_i \\in T$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Such approach is <font color=\"red\">impractical</font>, when the universe of items $U$ is large"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Example: $d = |U| = 1000$.  \n",
    "  In that case, there are a total of $(2^{1000} -1) > 10^{300}$ candidates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"figures/all-itemsets-lattice.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Brute-force optimization\n",
    "To make the brute-force approach **faster**:  \n",
    "* observing that `no` $(k + 1)$ `-patterns are frequent`  \n",
    "  if `no` $k$ `-patterns are frequent`.\n",
    "* Therefore, enumerate and **count the support** of all patterns with **increasing length** $l$ \n",
    "  * until for a certain length $l$, none of the candidates of length $l$ turn out to be frequent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* This is a <font color=\"red\">significant improvement</font> but **not satisfactory** for large values of $|U|$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example\n",
    "\n",
    "when $|U| = 1000$ and $l = 10$, the value of $\\sum_{i=1}^{10}\\binom{|U|}{i}$ is of the order of $10^{23}$ ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The Apriori Algorithm\n",
    "\n",
    "The **Apriori** algorithm\n",
    "* uses the <font color=\"red\">downward closure property</font> in order to **prune** the candidate search space.\n",
    "        Every subset of a frequent itemset is also frequent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* generates candidates with **smaller length k first** and counts their supports before generating candidates of length (k + 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* The resulting **frequent** *k-itemsets* are used to restrict the number of *(k + 1)-candidates* with the **downward closure property**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Apriori Algorithm\n",
    "\n",
    "* $F_k$ denote the set of frequent *k-itemsets* \n",
    "* $C_k$ denote the set of candidate *k-itemsets*\n",
    "* The **core of the approach** is to iteratively generate the *(k + 1)-candidates* $C_{k+1}$ from \n",
    "  **frequent k-itemsets** in $F_k$ already found by the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"figures/apriori-algorithm.png\" width=\"60%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Association Rules Mining\n",
    "\n",
    "The prototypical **example** of association rule learning is when \n",
    "* Amazon or another online retailer shows a list of   \n",
    "  \"`Customers who bought this item also bought...`\". \n",
    "\n",
    "In other words, **given some set of data, can we find some other data that is \"like it\"**.   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"figures/market-basket-example.webp\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Association rules\n",
    "\n",
    "* If-then rules about the content of the baskets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* $\\{i_1, i_2,\\dots, i_k\\} \\rightarrow j~$ means: \"if a basket contains all $\\{i_1, i_2,\\dots, i_k\\}$  then it is <font color='red'>likely</font> to contain $j$\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The model: rules\n",
    "\n",
    "* A basket or transaction $t_i$ <font color=\"red\">contains</font> $X$, a set of items (<font color=\"red\">itemset</font>) in $I$, if $X \\subseteq t_i$.\n",
    "* An <font color=\"red\">association rule</font> is an implication of the form:  \n",
    "  $X \\rightarrow Y$, where $X, Y \\subset I$, and $X \\cap Y = \\varnothing $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* An  <font color=\"red\">itemset</font> is a set of items.\n",
    "  * E.g., $X = \\{milk, bread, cereal\\}$ is an itemset.\n",
    "* A <font color=\"red\">k-itemset</font> is an itemset with <font color=\"red\">k items</font>.\n",
    "  * E.g., {milk, bread, cereal} is a 3-itemset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* <font color='red'>Confidence</font>  of this association rule is the **probability** of $j$ given $\\{i_1, i_2,\\dots, i_k\\}$ \n",
    "$$\\text{confidence}(j~|~\\{i_1, i_2,\\dots, i_k\\})=$$\n",
    "$$=\\frac{\\text{num. baskets containing both} ~j~ \\text{and}~\n",
    "\\{i_1, i_2,\\dots, i_k\\}}{\\text{num. baskets containing}~ \\{i_1, i_2,\\dots, i_k\\}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Support and Confidence\n",
    "\n",
    "<font color='red'>Support count</font>: The support count of an itemset X,   \n",
    "denoted by <font color='red'>X.count</font>,  \n",
    "in a data set T is the number of transactions in T that contain X. \n",
    "\n",
    "* Assume $T$ has $n$ transactions.  \n",
    "  Then, \n",
    "  $$support=\\frac{X.count}{n}$$\n",
    "  $$confidence=\\frac{(X \\cap Y).count}{X.count}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Goal and key features\n",
    "\n",
    "* <font color='red'>**Goal**</font>: Find all rules that satisfy the user-specified <font color='red'>minimum support</font> (*minsup*) and <font color='red'>minimum confidence</font> (*minconf*).\n",
    "* <font color='red'>Key Features</font>:\n",
    "  * <font color='red'>Completeness</font>: find all rules.\n",
    "  * <font color='red'>No target item(s)</font> on the right-hand-side\n",
    "  * Mining with data on <font color='red'>hard disk</font> (not in memory) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Generating rules: an example\n",
    "* Suppose {2,3,4} is frequent, with sup=50%\n",
    "* Proper nonempty subsets: {2,3}, {2,4}, {3,4}, {2}, {3}, {4},  \n",
    "  with sup=50%, 50%, 75%, 75%, 75%, 75% respectively\n",
    "* These generate these association rules:\n",
    "  * 2,3 $\\rightarrow$ 4, \tconfidence=100%\n",
    "  * 2,4 $\\rightarrow$ 3, \tconfidence=100%\n",
    "  * 3,4 $\\rightarrow$ 2, \tconfidence=67%\n",
    "  * 2 $\\rightarrow$ 3,4, \tconfidence=67%\n",
    "  * 3 $\\rightarrow$ 2,4, \tconfidence=67%\n",
    "  * 4 $\\rightarrow$ 2,3, \tconfidence=67%\n",
    "  * All rules have support = 50%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example of confidence\n",
    "\n",
    "\\begin{matrix}\n",
    " B_1 = \\{m, c, b\\} & B_2 = \\{m, p, j\\}  \\\\ \n",
    " B_3 = \\{m, b\\} & B_4 = \\{c, j\\}  \\\\ \n",
    " B_5 = \\{m, p, b\\} & B_6 = \\{m, c, b, j\\} \\\\\n",
    " B_7 = \\{c, b, j\\} & B_8 = \\{b, j\\} \n",
    "\\end{matrix}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* An association rule: $\\{m, b\\} \\rightarrow c$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Confidence = $2/4 = 50\\%$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Finding Association Rules\n",
    "\n",
    "* **Question**: `find alla association rules with support` $ \\ge s$ `and confidence ` $ \\ge c$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **Note**: \"`support`\" of an association rule is the support of the **set of items on the left**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **Hard part**: finding the frequent itemsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **Note**: if $\\{i_1, i_2,\\dots, i_k\\} \\rightarrow j~$ has high support and confidence, then both $\\{i_1, i_2,\\dots, i_k\\}$ and $\\{i_1, i_2,\\dots, i_k, j\\}$ will be \"`frequent`\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### More examples\n",
    "\n",
    "* What do you think would be the confidence for {Butter} → {Bread}? \n",
    "  * That is, what fraction of transactions having butter also had bread? \n",
    "  * Very high i.e. a value close to 1? That’s right. \n",
    "* What about {Yogurt} → {Milk}? High again. \n",
    "* {Toothbrush} → {Milk}? Not so sure? \n",
    "  * Confidence for this rule will also be high since {Milk} is such a frequent itemset and would be present in every other transaction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Introduce some numbers\n",
    "\n",
    "\n",
    "<img align=\"left\" style=\"padding-right:30px;\"  src=\"figures/association-rule-example.png\" width=\"30%\">\n",
    "\n",
    "\n",
    "* Consider the numbers from figure on the left. \n",
    "* Total transactions = 100. \n",
    "  * 10 of them have both milk and toothbrush, \n",
    "  * 70 have milk but no toothbrush and \n",
    "  * 4 have toothbrush but no milk.\n",
    "* **Confidence** for {Toothbrush} → {Milk} will be 10/(10+4) = 0.7\n",
    "* It's an High confidence value. But, <font color='red'>intuitively, these two products have a weak association</font>\n",
    "* **Lift** is introduced to overcome this challenge.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Lift\n",
    "* Lift is a very literal term given to this measure. \n",
    "* Think of it as the *lift* that {X} provides to our confidence for having {Y} on the cart. \n",
    "* Mathematically,\n",
    "$${\\mathrm  {lift}}(X\\Rightarrow Y)={\\frac  {{\\mathrm  {support}}(X\\cap Y)}{{\\mathrm  {support}}(X)\\times {\\mathrm  {support}}(Y)}}$$\n",
    "* If the lift is > 1, the rule is **potentially useful** for predicting the consequent in future data sets.\n",
    "* If the lift is < 1, means that presence of one item has **negative effect** on presence of other item and vice versa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Apriori algorithm example\n",
    "\n",
    "Take in data and **generate a list of association rules**. \n",
    "\n",
    "Let's take for <font color='red'>example</font> a <font color='red'>Netflix movie recommendor</font>. \n",
    "* We want to look at all of our users data and try to figure out **what movies a particular user might like** based on what they have seen. \n",
    "* For example, consider a user Jim. \n",
    "  * Jim just watched *The Dark Knight*. \n",
    "  * We know from our vast collection of data that people who watched *The Dark Knight* usually also watch *Deadpool* so logically we would recommend *Deadpool* to Jim. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Apriori algorithm for Netflix movie recommendor\n",
    "\n",
    "Continuing with our Netflix example, let us break down the algorithm:\n",
    "1. The first step of the algorithm is the <font color='red'>*support*</font> step. \n",
    "   * Given some movie $x$, the support for $x$ is given as \n",
    "   $$\\text{support}(x)=\\frac{\\text{number of users watching}~ x}{\\text{total number of users}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "2. The next step is the <font color='red'>*confidence*</font> step. \n",
    "   * Given two movies, $x$ and $y$, we can calculate the confidence of $y$ given $x$ as \n",
    "   $$\\text{confidence}(y|x)=\\frac{\\text{numbers of users who have seen both x and y}}{\\text{number of users who have seen x}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "3. The final computation is the <font color='red'>*lift*</font>. \n",
    "   * Again, given two movies $x$ and $y$, the lift of $y$ given $x$ is \n",
    "   $$\\text{lift}(y|x)=\\frac{confidence(y|x)}{support(y)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Now, we can build our aPriori algorithm.\n",
    "\n",
    "1. Set a **minimum support** and **confidence**.\n",
    "2. Take **all the subsets** in transactions having **higher support** than minimum support.\n",
    "3. Take **all the rules** of these subsets having **confidence higher** than the minimum confidence.\n",
    "4. **Sort** results by decreasing **lift**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Mining class association rules (CAR)\n",
    "\n",
    "* **Normal association rule** mining does not have any **target**. \n",
    "* It finds all possible rules that exist in data,  \n",
    "  i.e., `any item can appear as a consequent` or a condition of a rule. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* However, in some applications, the user is **interested in some targets**. \n",
    "* E.g, the user has a set of **text documents** from some **known topics**.  \n",
    "  He/she wants to find out what words are associated or correlated with each topic. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Problem definition\n",
    "* Let T be a transaction data set consisting of **n transactions**. \n",
    "* Each transaction is also **labeled** with a **class y**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Let \n",
    "  * I be the set of all items in T, \n",
    "  * Y be the set of all class labels and $I \\cap Y = \\varnothing$. \n",
    "* A <font color='red'>class association rule</font> (**CAR**) is an implication of the form \n",
    "  $X \\rightarrow y$, where $X \\subseteq I$, and $y \\in Y$. \n",
    "* The definitions of  <font color='red'>support</font> and  <font color='red'>confidence</font> are the same as those for normal association rules. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## An example\n",
    "* A text document data set\n",
    "        doc 1: \tStudent, Teach, School        : Education\n",
    "        doc 2: \tStudent, School               : Education \t\n",
    "        doc 3: \tTeach, School, City, Game     : Education\n",
    "        doc 4: \tBaseball, Basketball          : Sport\n",
    "        doc 5: \tBasketball, Player, Spectator : Sport\n",
    "        doc 6: \tBaseball, Coach, Game, Team   : Sport\n",
    "        doc 7: \tBasketball, Team, City, Game  : Sport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Let *minsup* = 20% and *minconf* = 60%. The following are two examples of **class association rules**:\n",
    "  * *Student*, *School* $\\rightarrow$ *Education*\t(sup= 2/7, conf = 2/2)\n",
    "  * *game* $\\rightarrow$ *Sport*\t\t\t    (sup= 2/7, conf = 2/3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Mining algorithm\n",
    "\n",
    "* Unlike normal association rules, CARs can be **mined** directly **in one step**. \n",
    "* The key operation is to find all <font color='red'>ruleitem</font> that have support above *minsup*.  \n",
    "  A <font color='red'>ruleitem</font> is of the form: (*condset*, $y$)  \n",
    "  where *condset* is a set of items from $I$ (i.e., *condset* $\\subseteq I$), and  $y \\in Y$ is a class label. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Each **ruleitem** basically represents a **rule**:  \n",
    "  *condset* $\\rightarrow y$,\n",
    "* The Apriori algorithm can be modified to generate CARs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Summary\n",
    "\n",
    "* Association rule mining **has been extensively studied** in the data mining community. \n",
    "* There are **many efficient algorithms** and model variations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Other related work includes\n",
    "  * Multi-level or generalized rule mining\n",
    "  * Constrained rule mining\n",
    "  * Incremental rule mining\n",
    "  * Maximal frequent itemset mining\n",
    "  * Numeric association rule mining\n",
    "  * Rule interestingness and visualization\n",
    "  * Parallel algorithms\n",
    "  * ... "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
